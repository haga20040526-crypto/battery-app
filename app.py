import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import datetime
import re
import altair as alt
import uuid
import time
import json
import threading
import os

# --- å®šæ•°ãƒ»è¨­å®š ---
PENALTY_LIMIT_DAYS = 28
NEW_SHEET_NAME = 'database' 
# ã‚¸ãƒ§ãƒ–IDåˆ—ã‚’å«ã‚€ãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©
EXPECTED_HEADERS = ['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'ä¿æœ‰é–‹å§‹æ—¥', 'å®Œäº†æ—¥', 'ã‚¨ãƒªã‚¢', 'é‡‘é¡', 'å‚™è€ƒ', 'ã‚¸ãƒ§ãƒ–ID']
ANALYTICS_CACHE_FILE = 'analytics_cache.json'

# --- ã‚¨ãƒªã‚¢å®šç¾© ---
ZONE_OPTIONS = [
    "D: ãã®ä»– (èˆ¹æ©‹ãªã©)", 
    "A: æ±äº¬23åŒº", 
    "B: æ±äº¬éƒ½ä¸‹", 
    "C: æŒ‡å®šéƒ½å¸‚(æ¨ªæµœç­‰)"
]
ZONES = {
    "D: ãã®ä»– (èˆ¹æ©‹ãªã©)": 70,
    "A: æ±äº¬23åŒº": 55,
    "B: æ±äº¬éƒ½ä¸‹": 65,
    "C: æŒ‡å®šéƒ½å¸‚(æ¨ªæµœç­‰)": 60,
}

# --- GCPè¨­å®š ---
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

def get_connection():
    if "gcp_service_account" not in st.secrets:
        st.error("ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: Secretsã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None
    creds_dict = st.secrets["gcp_service_account"]
    creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
    client = gspread.authorize(creds)
    return client

def get_today_jst():
    now = datetime.datetime.now() + datetime.timedelta(hours=9)
    return now.date()

def sanitize_for_json(val):
    if pd.isna(val): return ""
    if isinstance(val, (datetime.date, datetime.datetime)):
        return val.strftime('%Y-%m-%d')
    if hasattr(val, 'item'): return val.item()
    return str(val)

# --- ãƒ†ã‚­ã‚¹ãƒˆè§£æ ---
def extract_serials_with_date(text, default_date):
    results = []
    default_date_str = default_date.strftime('%Y-%m-%d')
    if text:
        text = text.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789'))
    else: return []
    
    date_pattern = re.compile(r'(\d{4})[-/.](\d{2})[-/.](\d{2})')
    serial_pattern = re.compile(r'\b(\d{8})\b')

    lines = [line.strip() for line in text.split('\n') if line.strip()]
    
    for i, line in enumerate(lines):
        serials_in_line = serial_pattern.findall(line)
        if not serials_in_line: continue
        
        search_window = lines[i : min(len(lines), i+4)]
        found_date = default_date_str
        for check_line in search_window:
            d_match = date_pattern.search(check_line)
            if d_match:
                found_date = f"{d_match.group(1)}-{d_match.group(2)}-{d_match.group(3)}"
                break
        
        for s in serials_in_line:
            results.append((s, found_date))
            
    if not results:
        all_serials = serial_pattern.findall(text)
        all_dates = date_pattern.findall(text)
        if all_serials:
            backup_date = f"{all_dates[0][0]}-{all_dates[0][1]}-{all_dates[0][2]}" if all_dates else default_date_str
            for s in all_serials: results.append((s, backup_date))

    unique_map = {r[0]: r[1] for r in results}
    return list(unique_map.items())

def extract_serials_only(text):
    if not text: return []
    text = text.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789'))
    return list(set(re.findall(r'\b\d{8}\b', text)))

# --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
def get_database():
    client = get_connection()
    if not client: return pd.DataFrame()
    try:
        try:
            sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
        except:
            wb = client.open('battery_db')
            sheet = wb.add_worksheet(title=NEW_SHEET_NAME, rows=1000, cols=10)
            sheet.append_row(EXPECTED_HEADERS)

        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        
        if df.empty: return pd.DataFrame(columns=EXPECTED_HEADERS)
        
        # ã‚«ãƒ©ãƒ ä¸è¶³ã®è£œæ­£
        current_cols = df.columns.tolist()
        if 'ã‚¸ãƒ§ãƒ–ID' not in current_cols:
            sheet.update_cell(1, len(current_cols) + 1, 'ã‚¸ãƒ§ãƒ–ID')
            df['ã‚¸ãƒ§ãƒ–ID'] = ""

        df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'] = df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].astype(str)
        if 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in df.columns:
            df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] = df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'].astype(str).str.strip()
        
        df['é‡‘é¡'] = pd.to_numeric(df['é‡‘é¡'], errors='coerce').fillna(0).astype(int)
        for col in ['ä¿æœ‰é–‹å§‹æ—¥', 'å®Œäº†æ—¥']:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
        return df
    except: return pd.DataFrame()

def get_active_inventory(df_all):
    if df_all.empty or 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' not in df_all.columns: return pd.DataFrame()
    df = df_all[df_all['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'åœ¨åº«'].copy()
    if not df.empty:
        df = df.sort_values(by=['ä¿æœ‰é–‹å§‹æ—¥'], ascending=[True])
        return df
    return df

def get_vol_bonus(count):
    if count >= 150: return 20
    elif count >= 100: return 15
    elif count >= 50: return 10
    elif count >= 20: return 5
    else: return 0

# --- åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Analytics Logic) ---

def calculate_analytics_logic(df):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œç”¨ï¼‰
    """
    if df.empty: return {}

    # æ—¥ä»˜å¤‰æ›
    df['completed_at'] = pd.to_datetime(df['å®Œäº†æ—¥'], errors='coerce')
    df['acquired_at'] = pd.to_datetime(df['ä¿æœ‰é–‹å§‹æ—¥'], errors='coerce')
    
    # å®Œäº†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
    completed_df = df[df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'è£œå……æ¸ˆ'].copy()
    completed_df = completed_df.dropna(subset=['completed_at', 'acquired_at'])
    completed_df['holding_days'] = (completed_df['completed_at'] - completed_df['acquired_at']).dt.days

    # --- 1. KPIè¨ˆç®— ---
    # Early Bonus Rate (ç›´è¿‘30æ—¥)
    today = datetime.datetime.now()
    month_ago = today - datetime.timedelta(days=30)
    recent_df = completed_df[completed_df['completed_at'] >= month_ago]
    
    early_rate = 0
    if len(recent_df) > 0:
        early_count = len(recent_df[recent_df['holding_days'] <= 3])
        early_rate = (early_count / len(recent_df)) * 100

    # RPD (Revenue Per Day)
    total_rev = completed_df['é‡‘é¡'].sum()
    total_days = completed_df['holding_days'].sum()
    # 0æ—¥ä¿æœ‰ã‚‚1æ—¥ã¨ã¿ãªã™ã‹ã€ãã®ã¾ã¾è¨ˆç®—ã™ã‚‹ã‹ã€‚ã“ã“ã§ã¯0é™¤ç®—å›é¿ã®ã¿ã€‚
    if total_days == 0: total_days = 1 
    rpd = total_rev / total_days

    # Avg Holding Days
    avg_holding = completed_df['holding_days'].mean() if len(completed_df) > 0 else 0

    # --- 2. ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ‡ãƒ¼ã‚¿ ---
    # Zone A(0-3), B(4-22), C(23+)
    hist_counts = completed_df['holding_days'].value_counts().sort_index().to_dict()
    # ã‚­ãƒ¼ã‚’æ–‡å­—åˆ—åŒ–ã—ã¦JSONä¿å­˜å¯èƒ½ã«
    hist_data = {str(k): int(v) for k, v in hist_counts.items()}

    # --- 3. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ (æ›œæ—¥åˆ¥æ´»å‹•é‡) ---
    # æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€æ›œæ—¥ã”ã¨ã®å®Œäº†æ•°ã§ä»£ç”¨
    completed_df['weekday'] = completed_df['completed_at'].dt.day_name()
    # æ™‚é–“å¸¯ã¯ãƒ€ãƒŸãƒ¼(Day)ã¨ã™ã‚‹ã‹ã€å°†æ¥ã®æ‹¡å¼µã«å‚™ãˆã‚‹
    completed_df['time_zone'] = 'Day' 
    heatmap_series = completed_df.groupby(['weekday', 'time_zone']).size()
    heatmap_data = []
    for (wd, tz), count in heatmap_series.items():
        heatmap_data.append({'weekday': wd, 'time_zone': tz, 'count': int(count)})

    # --- 4. æ¨ç§»åˆ†æ (é€±æ¬¡ å¹³å‡ä¿æœ‰æ—¥æ•°) ---
    three_months_ago = today - datetime.timedelta(days=90)
    trend_df = completed_df[completed_df['completed_at'] >= three_months_ago].copy()
    trend_df['week'] = trend_df['completed_at'].dt.to_period('W').astype(str)
    trend_series = trend_df.groupby('week')['holding_days'].mean()
    trend_data = [{'week': w, 'avg_days': round(d, 2)} for w, d in trend_series.items()]

    return {
        "kpi": {
            "early_bonus_rate": round(early_rate, 1),
            "rpd": round(rpd, 1),
            "avg_holding_days": round(avg_holding, 1)
        },
        "histogram": hist_data,
        "heatmap": heatmap_data,
        "trend": trend_data,
        "updated_at": today.strftime('%Y-%m-%d %H:%M:%S')
    }

def update_analytics_background():
    """
    ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã§KPIã‚’å†è¨ˆç®—ã—ã¦JSONã«ä¿å­˜
    """
    def task():
        # DBã‹ã‚‰æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰å†…ã§å®‰å…¨ã«è¡Œã†ãŸã‚å†å–å¾—ï¼‰
        # â€»Streamlitã®Secretsã¯ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã§ã‚‚å‚ç…§å¯èƒ½
        try:
            df = get_database()
            if df.empty: return
            
            data = calculate_analytics_logic(df)
            with open(ANALYTICS_CACHE_FILE, 'w') as f:
                json.dump(data, f)
            # print("Analytics updated in background.")
        except Exception as e:
            print(f"Background update failed: {e}")

    thread = threading.Thread(target=task)
    thread.start()

def load_analytics_cache():
    if not os.path.exists(ANALYTICS_CACHE_FILE):
        return None
    try:
        with open(ANALYTICS_CACHE_FILE, 'r') as f:
            return json.load(f)
    except:
        return None

# --- æ›¸ãè¾¼ã¿ãƒ»è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ (ãƒˆãƒªã‚¬ãƒ¼è¿½åŠ ç‰ˆ) ---

def register_new_inventory(data_list):
    client = get_connection()
    sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
    all_records = sheet.get_all_records()
    df = pd.DataFrame(all_records)
    
    current_active_serials = set()
    if not df.empty and 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in df.columns:
        active_df = df[df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'].astype(str).str.strip().isin(['åœ¨åº«', 'å‡ºåº«ä¸­'])]
        current_active_serials = set(active_df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].astype(str).tolist())
    
    headers = sheet.row_values(1)
    if not headers: sheet.append_row(EXPECTED_HEADERS)

    rows = []
    skipped = 0
    for s, d in data_list:
        s_str = str(s)
        if s_str in current_active_serials:
            skipped += 1
            continue
        row = [sanitize_for_json(s_str), "åœ¨åº«", sanitize_for_json(d), "", "", "", "", ""]
        rows.append(row)
    
    if rows:
        try: 
            sheet.append_rows(rows)
            # â˜…ãƒˆãƒªã‚¬ãƒ¼: åˆ†æãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ›´æ–°
            update_analytics_background()
        except: return 0, 0
    return len(rows), skipped

def register_past_bulk(date_obj, count, total_amount, zone, memo="", job_id=""):
    client = get_connection()
    sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
    headers = sheet.row_values(1)
    if not headers: sheet.append_row(EXPECTED_HEADERS)
    if count <= 0: return 0
    
    base_amount = total_amount // count
    remainder = total_amount % count
    date_str = date_obj.strftime('%Y-%m-%d')
    rows = []
    for i in range(count):
        dummy_sn = f"OLD-{date_str.replace('-','')}-{uuid.uuid4().hex[:6]}"
        amount = base_amount + (1 if i < remainder else 0)
        row = [dummy_sn, "è£œå……æ¸ˆ", "", date_str, zone, amount, memo, job_id]
        rows.append(row)
    if rows: 
        sheet.append_rows(rows)
        # â˜…ãƒˆãƒªã‚¬ãƒ¼: åˆ†æãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ›´æ–°
        update_analytics_background()

    return len(rows)

def recalc_weekly_revenue(sheet, today_date):
    all_records = sheet.get_all_records()
    headers = sheet.row_values(1)
    try: col_price = headers.index('é‡‘é¡') + 1
    except: return 0

    start_of_week = today_date - datetime.timedelta(days=today_date.weekday())
    end_of_week = start_of_week + datetime.timedelta(days=6)

    weekly_indices = []
    for i, row in enumerate(all_records):
        st_val = str(row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')).strip()
        comp_date_str = str(row.get('å®Œäº†æ—¥', ''))
        memo = str(row.get('å‚™è€ƒ', ''))
        
        if st_val == 'è£œå……æ¸ˆ' and comp_date_str and 'ãƒœãƒ¼ãƒŠã‚¹' not in memo:
            try:
                comp_date = datetime.datetime.strptime(comp_date_str, '%Y-%m-%d').date()
                if start_of_week <= comp_date <= end_of_week:
                    weekly_indices.append(i)
            except: pass

    week_count = len(weekly_indices)
    current_bonus = get_vol_bonus(week_count)
    
    cells_to_update = []
    for idx in weekly_indices:
        row = all_records[idx]
        zone_name = str(row.get('ã‚¨ãƒªã‚¢', ''))
        base_price = ZONES.get(zone_name, 70)
        start_d_str = str(row.get('ä¿æœ‰é–‹å§‹æ—¥', ''))
        end_d_str = str(row.get('å®Œäº†æ—¥', ''))
        early_bonus = 0
        try:
            s_date = datetime.datetime.strptime(start_d_str, '%Y-%m-%d').date()
            e_date = datetime.datetime.strptime(end_d_str, '%Y-%m-%d').date()
            if (e_date - s_date).days <= 3: early_bonus = 10
        except: pass
        
        new_total_price = base_price + current_bonus + early_bonus
        if row.get('é‡‘é¡', 0) != new_total_price:
            cells_to_update.append(gspread.Cell(idx + 2, col_price, new_total_price))

    if cells_to_update:
        try: sheet.update_cells(cells_to_update)
        except: pass
    return len(cells_to_update)

def update_status_bulk(target_serials, new_status, complete_date=None, zone="", price=0, memo="", job_id=""):
    client = get_connection()
    sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
    all_records = sheet.get_all_records()
    headers = sheet.row_values(1)
    
    try:
        col_status = headers.index('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹') + 1
        col_end = headers.index('å®Œäº†æ—¥') + 1
        col_zone = headers.index('ã‚¨ãƒªã‚¢') + 1
        col_price = headers.index('é‡‘é¡') + 1
        col_memo = headers.index('å‚™è€ƒ') + 1
        col_job = headers.index('ã‚¸ãƒ§ãƒ–ID') + 1 if 'ã‚¸ãƒ§ãƒ–ID' in headers else None
    except: return 0

    cells = []
    updated = 0
    target_set = set(str(s) for s in target_serials)
    comp_str = sanitize_for_json(complete_date)
    safe_price = int(price)
    
    permitted_statuses = ['åœ¨åº«', 'å‡ºåº«ä¸­']

    for i, row in enumerate(all_records):
        s = str(row.get('ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼', ''))
        st_val = str(row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')).strip()
        
        if st_val in permitted_statuses and s in target_set:
            r = i + 2
            cells.append(gspread.Cell(r, col_status, new_status))
            cells.append(gspread.Cell(r, col_end, comp_str))
            cells.append(gspread.Cell(r, col_zone, zone))
            cells.append(gspread.Cell(r, col_price, safe_price))
            if memo: cells.append(gspread.Cell(r, col_memo, memo))
            if col_job and job_id: cells.append(gspread.Cell(r, col_job, job_id))
            updated += 1
            
    if cells:
        try: sheet.update_cells(cells)
        except: return 0
    
    if updated > 0 and new_status == 'è£œå……æ¸ˆ' and complete_date:
        recalc_weekly_revenue(sheet, complete_date)
        # â˜…ãƒˆãƒªã‚¬ãƒ¼: åˆ†æãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ›´æ–°
        update_analytics_background()

    return updated

# --- UIãƒ‘ãƒ¼ãƒ„ ---
def create_card(row, today):
    start_date = row.get('ä¿æœ‰é–‹å§‹æ—¥')
    status = str(row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')).strip()
    sn = row['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼']
    last4 = sn[-4:]
    
    if pd.isnull(start_date):
        s_str, days = "-", 0
    else:
        s_str = start_date.strftime('%m/%d')
        days = (today - start_date).days
    
    if status == 'è£œå……æ¸ˆ':
        c, bg, st_t, bd = "#1565c0", "#e3f2fd", "âœ… å®Œäº†", "#2196f3"
        date_label = f"å®Œäº†: {s_str}"
        main_text = "è£œå……æ¸ˆ"
    elif status == 'å‡ºåº«ä¸­':
        c, bg, st_t, bd = "#f57c00", "#fff3e0", "ğŸšš å‡ºåº«ä¸­", "#ff9800"
        date_label = f"å–å¾—: {s_str}"
        main_text = last4
    elif status == 'ä¸æ˜' or 'å‰Šé™¤' in status or 'ã‚¨ãƒ©ãƒ¼' in status:
        c, bg, st_t, bd = "#757575", "#f5f5f5", "ğŸš« é™¤å¤–", "#bdbdbd"
        date_label = "-"
        main_text = "é™¤å¤–æ¸ˆ"
    else:
        p_days = PENALTY_LIMIT_DAYS - days
        if p_days <= 5: 
            c, bg, st_t, bd = "#c62828", "#ffebee", f"ğŸ”¥ æ®‹{p_days}æ—¥", "#ef5350"
        elif days <= 3: 
            c, bg, st_t, bd = "#2e7d32", "#e8f5e9", "ğŸ’ Bonuså¯¾è±¡", "#66bb6a"
        else: 
            c, bg, st_t, bd = "#424242", "#ffffff", "ğŸ¢ é€šå¸¸", "#bdbdbd"
        date_label = f"å–å¾—: {s_str}"
        main_text = last4

    html = f"""
    <div style="background:{bg}; border-radius:8px; border-left:6px solid {bd}; padding:10px; margin-bottom:8px; box-shadow:0 1px 3px rgba(0,0,0,0.1);">
        <div style="display:flex; justify-content:space-between; font-size:11px; font-weight:bold; color:{c};">
            <div>{st_t}</div><div>{date_label}</div>
        </div>
        <div style="font-size:28px; font-weight:900; color:#212121; margin-top:2px; letter-spacing:1px;">{main_text}</div>
        <div style="text-align:right; font-size:9px; color:#999; font-family:monospace;">{sn}</div>
    </div>
    """
    return html

def create_history_card(row):
    comp_date = pd.to_datetime(row['å®Œäº†æ—¥']).strftime('%m/%d')
    amount = row['é‡‘é¡']
    memo = str(row['å‚™è€ƒ'])
    sn = str(row['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'])
    zone = str(row['ã‚¨ãƒªã‚¢'])
    job_id = str(row.get('ã‚¸ãƒ§ãƒ–ID', ''))
    
    if "ãƒœãƒ¼ãƒŠã‚¹" in memo or "å·®é¡" in memo:
        job_type = "ãƒœãƒ¼ãƒŠã‚¹/èª¿æ•´"
        icon = "âœ¨"
        bg = "#fff8e1"
        border = "#ffb300"
        sn_disp = memo
    elif "ã‚¨ãƒ©ãƒ¼" in memo:
        job_type = "ã‚¨ãƒ©ãƒ¼å‡¦ç†"
        icon = "âš ï¸"
        bg = "#ffebee"
        border = "#ef5350"
        sn_disp = f"SN: {sn[-4:]}"
    else:
        job_type = "ãƒãƒƒãƒ†ãƒªãƒ¼è£œå……"
        icon = "ğŸ”‹"
        bg = "#ffffff"
        border = "#e0e0e0"
        sn_disp = f"SN: {sn[-4:]} ({zone})"
        if job_id:
            # ã‚¸ãƒ§ãƒ–IDã‚’è¡¨ç¤º
            sn_disp += f" <span style='color:#1565c0; font-size:10px;'>[{job_id}]</span>"

    html = f"""<div style="background:{bg}; border:1px solid {border}; border-radius:8px; padding:10px 14px; margin-bottom:8px; display:flex; align-items:center; box-shadow: 0 1px 2px rgba(0,0,0,0.05);"><div style="font-size:24px; margin-right:12px;">{icon}</div><div style="flex-grow:1;"><div style="font-size:13px; font-weight:bold; color:#424242;">{job_type}</div><div style="font-size:11px; color:#757575;">{comp_date} | {sn_disp}</div></div><div style="text-align:right;"><div style="font-size:16px; font-weight:900; color:#212121;">Â¥{amount}</div></div></div>"""
    return html

# --- ãƒ¡ã‚¤ãƒ³ ---
def main():
    st.set_page_config(page_title="Battery Manager V32", page_icon="âš¡", layout="wide")
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""<div style='display: flex; align-items: center; border-bottom: 2px solid #ff7043; padding-bottom: 10px; margin-bottom: 20px;'><div style='font-size: 40px; margin-right: 15px;'>âš¡</div><div><h1 style='margin: 0; padding: 0; font-size: 32px; color: #333; font-family: sans-serif; letter-spacing: -1px;'>Battery Manager</h1><div style='font-size: 14px; color: #757575;'>Recorder to Strategist <span style='color: #ff7043; font-weight: bold; margin-left:8px;'>V32</span></div></div></div>""", unsafe_allow_html=True)

    st.markdown("<style>.stSlider{padding-top:1rem;}</style>", unsafe_allow_html=True)
    today = get_today_jst()

    if 'stocktake_buffer' not in st.session_state: st.session_state['stocktake_buffer'] = []
    if 'parsed_data' not in st.session_state: st.session_state['parsed_data'] = None

    df_all = get_database()
    
    if not df_all.empty and 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in df_all.columns:
        df_valid = df_all[~df_all['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'].str.contains('å‰Šé™¤', na=False)]
        df_inv = get_active_inventory(df_valid)
        df_hist = df_valid[df_valid['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] != 'åœ¨åº«'].copy()
    else:
        df_inv = pd.DataFrame()
        df_hist = pd.DataFrame()

    week_earnings = 0
    last_week_earnings = 0
    week_count = 0
    next_bonus_at = 20
    
    if not df_hist.empty:
        start_of_week = today - datetime.timedelta(days=today.weekday())
        last_week_start = start_of_week - datetime.timedelta(days=7)
        
        df_hist['comp_date'] = pd.to_datetime(df_hist['å®Œäº†æ—¥'], errors='coerce')
        
        w_df = df_hist[
            (df_hist['comp_date'].dt.date >= start_of_week) & 
            (df_hist['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'è£œå……æ¸ˆ')
        ].copy()
        
        lw_df = df_hist[
            (df_hist['comp_date'].dt.date >= last_week_start) & 
            (df_hist['comp_date'].dt.date < start_of_week) & 
            (df_hist['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'è£œå……æ¸ˆ')
        ].copy()

        count_mask = w_df.apply(lambda x: 'ãƒœãƒ¼ãƒŠã‚¹' not in str(x['å‚™è€ƒ']), axis=1)
        week_count = len(w_df[count_mask])
        week_earnings = int(w_df['é‡‘é¡'].sum())
        last_week_earnings = int(lw_df['é‡‘é¡'].sum())
        
        if week_count < 20: next_bonus_at = 20
        elif week_count < 50: next_bonus_at = 50
        elif week_count < 100: next_bonus_at = 100
        elif week_count < 150: next_bonus_at = 150
        else: next_bonus_at = 999

    cur_bonus = get_vol_bonus(week_count)

    if next_bonus_at != 999:
        remain = next_bonus_at - week_count
        st.caption(f"ğŸ”¥ ä»Šé€±ã®ç›®æ¨™: {next_bonus_at}æœ¬ã¾ã§ ã‚ã¨**{remain}æœ¬**")
        st.progress(min(week_count / next_bonus_at, 1.0))
    else:
        st.success(f"ğŸ‘‘ MAXãƒ©ãƒ³ã‚¯åˆ°é”ï¼ (+{cur_bonus}å††)")

    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ  ãƒ›ãƒ¼ãƒ ", "ğŸ” æ¤œç´¢", "ğŸ“¦ åœ¨åº«", "ğŸ’° åç›Š", "ğŸ“ æ£šå¸", "ğŸ“Š åˆ†æ"])

    # 1. ãƒ›ãƒ¼ãƒ 
    with tab1:
        c1, c2, c3 = st.columns(3)
        c1.metric("å ±é…¬", f"Â¥ {week_earnings:,}", delta=f"{week_earnings - last_week_earnings:,} å†† (å…ˆé€±æ¯”)")
        c2.metric("æœ¬æ•°", f"{week_count} æœ¬")
        c3.metric("ç¾åœ¨ãƒœãƒŠ", f"+{cur_bonus}å††/æœ¬")
        st.divider()

        mode = st.radio("ä½œæ¥­ãƒ¢ãƒ¼ãƒ‰", ["å–å‡º (ç™»éŒ²)", "è£œå…… (ç¢ºå®š)"], horizontal=True)
        
        if mode == "å–å‡º (ç™»éŒ²)":
            txt = st.text_area("ãƒªã‚¹ãƒˆè²¼ä»˜", height=100, placeholder="ä¿æœ‰ä¸­ãƒªã‚¹ãƒˆã‚’ã“ã“ã«ãƒšãƒ¼ã‚¹ãƒˆ")
            date_in = st.date_input("åŸºæº–æ—¥ (èª­å–ä¸å¯æ™‚)", value=today)
            if st.button("èª­è¾¼", icon=":material/search:"):
                if txt:
                    parsed = extract_serials_with_date(txt, date_in)
                    st.session_state['parsed_data'] = parsed
                    if parsed: st.success(f"{len(parsed)} ä»¶ èª­è¾¼")
                    else: st.warning("ç•ªå·ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            if st.session_state['parsed_data']:
                st.dataframe(pd.DataFrame(st.session_state['parsed_data'], columns=["SN","æ—¥ä»˜"]), hide_index=True)
                if st.button("ç™»éŒ²å®Ÿè¡Œ", type="primary", use_container_width=True):
                    cnt, skip = register_new_inventory(st.session_state['parsed_data'])
                    msg = f"âœ… {cnt}ä»¶ ç™»éŒ²"
                    if skip > 0: msg += f" (æ‰‹å…ƒé‡è¤‡ {skip}ä»¶ ã‚¹ã‚­ãƒƒãƒ—)"
                    st.success(msg)
                    st.session_state['parsed_data'] = None
                    time.sleep(1)
                    st.rerun()

        else: 
            col_d, col_z = st.columns([1,1])
            date_done = col_d.date_input("è£œå……æ—¥", value=today)
            zone = col_z.selectbox("ã‚¨ãƒªã‚¢", ZONE_OPTIONS)
            
            txt = st.text_area("ãƒªã‚¹ãƒˆè²¼ä»˜", height=100, placeholder="å®Œäº†ç”»é¢ã‚’ã“ã“ã«ãƒšãƒ¼ã‚¹ãƒˆ")
            if txt:
                sns = extract_serials_only(txt)
                if sns:
                    st.info(f"{len(sns)}ä»¶ æ¤œå‡º")
                    if st.button("è£œå……ç¢ºå®š", type="primary", use_container_width=True):
                        base = ZONES[zone]
                        # è‡ªå‹•ã‚¸ãƒ§ãƒ–IDç”Ÿæˆ
                        now_str = datetime.datetime.now().strftime('%Y%m%d%H%M%S')
                        auto_job_id = f"J{now_str}"
                        
                        cnt = update_status_bulk(sns, "è£œå……æ¸ˆ", date_done, zone, base, job_id=auto_job_id)
                        if cnt > 0:
                            st.success(f"{cnt}ä»¶ æ›´æ–°ã—ã¾ã—ãŸ (ID: {auto_job_id})")
                        else:
                            st.warning("æ›´æ–°ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åœ¨åº«ã¾ãŸã¯å‡ºåº«ä¸­ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        time.sleep(1)
                        st.rerun()

        st.divider()
        st.markdown("##### ğŸ“Œ ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ— (å„ªå…ˆé †)")
        col_sl, _ = st.columns([1,2])
        with col_sl:
            disp_count = st.slider("è¡¨ç¤ºæ•°", 4, 40, 8, step=4)

        if not df_inv.empty:
            df_disp = df_inv.copy()
            def get_priority(row):
                days = (today - row['ä¿æœ‰é–‹å§‹æ—¥']).days
                if days >= (PENALTY_LIMIT_DAYS - 5): return 1
                if days <= 3: return 2
                return 3
            df_disp['rank'] = df_disp.apply(get_priority, axis=1)
            df_disp = df_disp.sort_values(by=['rank', 'ä¿æœ‰é–‹å§‹æ—¥'], ascending=[True, True])
            
            top_n = df_disp.head(disp_count)
            for i in range(0, len(top_n), 4):
                cols = st.columns(4)
                chunk = top_n.iloc[i:i+4]
                for j, (_, row) in enumerate(chunk.iterrows()):
                    with cols[j]:
                        st.markdown(create_card(row, today), unsafe_allow_html=True)
        else: st.info("ç¾åœ¨ã€åœ¨åº«ã¯ã‚ã‚Šã¾ã›ã‚“")

    # 2. æ¤œç´¢
    with tab2:
        date_options = ["æŒ‡å®šãªã—"]
        date_map = {}
        if not df_inv.empty:
            unique_dates = sorted(df_inv['ä¿æœ‰é–‹å§‹æ—¥'].unique(), reverse=True)
            for d in unique_dates:
                if pd.notnull(d):
                    label = d.strftime('%m/%d')
                    date_options.append(label)
                    date_map[label] = d

        c_s1, c_s2 = st.columns(2)
        with c_s1:
            sel_date = st.selectbox("ä¿æœ‰é–‹å§‹æ—¥ (åœ¨åº«ã®ã¿)", date_options)
        with c_s2:
            sn_in = st.number_input("SNä¸‹4æ¡", 0, 9999, 0)

        results = pd.DataFrame()
        
        if sel_date != "æŒ‡å®šãªã—":
            target_date = date_map[sel_date]
            results = df_inv[df_inv['ä¿æœ‰é–‹å§‹æ—¥'] == target_date].copy()
            if sn_in > 0:
                results = results[results['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].str.endswith(str(sn_in))]
            
            if not results.empty:
                st.success(f"{len(results)}ä»¶ (ä¿æœ‰æ—¥: {sel_date})")
                for _, row in results.iterrows():
                    st.markdown(create_card(row, today), unsafe_allow_html=True)
            else:
                st.warning("è©²å½“ãªã—")

        elif sn_in > 0:
            if not df_all.empty:
                results = df_all[df_all['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].str.endswith(str(sn_in))]
                if not results.empty:
                    st.success(f"{len(results)}ä»¶ ãƒ’ãƒƒãƒˆ (å…¨æœŸé–“)")
                    for _, row in results.iterrows():
                        st.markdown(create_card(row, today), unsafe_allow_html=True)
                else:
                    st.warning("ãªã—")
        else:
            st.info("æ¡ä»¶ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")

    # 3. åœ¨åº«
    with tab3:
        st.metric("åœ¨åº«æ•°", f"{len(df_inv)}")
        if not df_inv.empty:
            st.dataframe(df_inv[['ä¿æœ‰é–‹å§‹æ—¥', 'ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼']], use_container_width=True)

    # 4. åç›Š
    with tab4:
        st.metric("ä»Šé€±", f"Â¥{week_earnings:,}", delta=f"{week_earnings - last_week_earnings:,} å†† (å…ˆé€±æ¯”)")
        
        with st.expander("â• éå»ãƒ‡ãƒ¼ã‚¿ã®ç™»éŒ²"):
            with st.form("manual_past_reg"):
                c1, c2 = st.columns(2)
                p_date = c1.date_input("å®Œäº†æ—¥")
                p_count = c2.number_input("æ•°é‡", min_value=1, value=1)
                p_amount = c1.number_input("åˆè¨ˆé‡‘é¡", step=10)
                p_zone = c2.selectbox("ã‚¨ãƒªã‚¢", ZONE_OPTIONS)
                p_memo = st.text_input("å‚™è€ƒ", placeholder="ãƒœãƒ¼ãƒŠã‚¹ãªã©")
                
                if st.form_submit_button("ç™»éŒ²"):
                    # è‡ªå‹•ã‚¸ãƒ§ãƒ–IDç”Ÿæˆ
                    now_str = datetime.datetime.now().strftime('%Y%m%d%H%M%S')
                    auto_job_id = f"J{now_str}"
                    
                    reg_cnt = register_past_bulk(p_date, p_count, p_amount, p_zone, p_memo, job_id=auto_job_id)
                    st.success(f"{reg_cnt}è¡Œ ç™»éŒ²å®Œäº† (ID: {auto_job_id})")
                    time.sleep(1)
                    st.rerun()

        if not df_hist.empty:
            df_wk = df_hist[df_hist['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'è£œå……æ¸ˆ'].copy()
            if not df_wk.empty:
                df_wk['date'] = pd.to_datetime(df_wk['å®Œäº†æ—¥'])
                df_wk['week_start'] = df_wk['date'].apply(lambda x: x - datetime.timedelta(days=x.weekday()))
                df_wk['is_battery'] = df_wk['å‚™è€ƒ'].apply(lambda x: 0 if 'ãƒœãƒ¼ãƒŠã‚¹' in str(x) else 1)
                
                weekly_agg = df_wk.groupby('week_start').agg(
                    total_amount=('é‡‘é¡', 'sum'),
                    count=('is_battery', 'sum')
                ).reset_index().sort_values('week_start', ascending=False)
                weekly_agg['Label'] = weekly_agg['week_start'].dt.strftime('%Y/%m/%d') + " é€±"

                st.divider()
                st.subheader("ğŸ“Š å±¥æ­´ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³")
                
                if 'orig_index' not in df_wk.columns:
                    df_wk['orig_index'] = df_wk.index
                recent_history = df_wk.sort_values(by=['date', 'orig_index'], ascending=[False, False]).head(30)
                
                for _, row in recent_history.iterrows():
                    st.markdown(create_history_card(row), unsafe_allow_html=True)

                st.divider()
                st.subheader("ğŸ“ˆ é€±æ¬¡æ¯”è¼ƒ")
                
                chart_data = weekly_agg.sort_values('week_start', ascending=True)
                base = alt.Chart(chart_data).encode(x=alt.X('Label', sort=None, title='é€±'))
                bar = base.mark_bar(color='#ffcc80').encode(
                    y=alt.Y('total_amount', title='é‡‘é¡', axis=alt.Axis(titleColor='#ff7043')),
                    tooltip=['Label', 'total_amount', 'count']
                )
                line = base.mark_line(color='#ff7043', strokeWidth=3).encode(
                    y=alt.Y('count', title='æœ¬æ•°', axis=alt.Axis(titleColor='#ff7043'))
                )
                points = base.mark_circle(color='#ff7043', size=60).encode(
                    y=alt.Y('count', axis=None)
                )
                st.altair_chart(alt.layer(bar, line + points).resolve_scale(y='independent').properties(height=300), use_container_width=True)
                
                st.markdown("##### ğŸ“… é€±é–“é›†è¨ˆ")
                display_df = weekly_agg[['Label', 'total_amount', 'count']].rename(
                    columns={'Label': 'é€± (æœˆæ›œé–‹å§‹)', 'total_amount': 'åˆè¨ˆé‡‘é¡ (å††)', 'count': 'æœ¬æ•° (æœ¬)'}
                )
                st.dataframe(display_df, hide_index=True, use_container_width=True)

    # 5. æ£šå¸
    with tab5:
        st.subheader("åœ¨åº«æ£šå¸ã—")
        cur = st.session_state['stocktake_buffer']
        c1, c2 = st.columns([1,1])
        with c1:
            txt_stock = st.text_area("å…¨ãƒªã‚¹ãƒˆè²¼ä»˜")
            if st.button("ãƒªã‚¹ãƒˆã‚’èª­è¾¼"):
                if txt_stock:
                    add = extract_serials_with_date(txt_stock, today)
                    st.session_state['stocktake_buffer'] = add
                    st.rerun()
            if st.button("ã‚¯ãƒªã‚¢"):
                st.session_state['stocktake_buffer'] = []
                st.rerun()
        with c2:
            st.caption(f"èª­è¾¼: {len(cur)}ä»¶")
            if cur: st.dataframe(pd.DataFrame(cur, columns=["SN","æ—¥ä»˜"]), height=150, hide_index=True)

        st.divider()
        if cur:
            s_map = {s:d for s,d in cur}
            input_set = set(s_map.keys())
            db_map = {}
            if not df_inv.empty:
                db_map = dict(zip(df_inv['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'], df_inv['ä¿æœ‰é–‹å§‹æ—¥']))
            db_set = set(db_map.keys())
            missing_db = []
            for s, d in s_map.items():
                if s not in db_map: missing_db.append((s, d))
            ghosts = list(db_set - input_set)
            
            c_act1, c_act2 = st.columns(2)
            with c_act1:
                st.markdown(f"**â‘  æ–°è¦åœ¨åº«: {len(missing_db)}ä»¶**")
                if missing_db:
                    if st.button("æ–°è¦åˆ†ã‚’ç™»éŒ²", type="primary"):
                        cnt, _ = register_new_inventory(missing_db)
                        st.success(f"{cnt}ä»¶ ç™»éŒ²ã—ã¾ã—ãŸ")
                        time.sleep(1)
                        st.rerun()
            with c_act2:
                st.markdown(f"**â‘¡ æ¶ˆå¤±ãƒ»ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥: {len(ghosts)}ä»¶**")
                if ghosts:
                    st.warning("åœ¨åº«å·®ç•°ã‚ã‚Š")
                    with st.expander("è©³ç´°"): st.write(ghosts)
                    if st.button("ä¸€æ‹¬ã€Œè£œå……ã‚¨ãƒ©ãƒ¼ã€ã«ã™ã‚‹"):
                        cnt = update_status_bulk(ghosts, "è£œå……ã‚¨ãƒ©ãƒ¼", today, "", 0, "æ£šå¸æ¤œçŸ¥")
                        st.success(f"{cnt}ä»¶ ã‚’åœ¨åº«ã‹ã‚‰é™¤å¤–ã—ã¾ã—ãŸ")
                        time.sleep(1)
                        st.rerun()
                else: st.success("å·®ç•°ãªã—")

    # 6. åˆ†æ (Analytics)
    with tab6:
        st.subheader("ğŸ“Š Analytics: Strategist Mode")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        analytics_data = load_analytics_cache()
        
        if not analytics_data:
            st.info("ç¾åœ¨ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆä¸­ã§ã™ã€‚ä½•ã‚‰ã‹ã®ã‚¸ãƒ§ãƒ–ï¼ˆè£œå……ãƒ»ç™»éŒ²ãªã©ï¼‰ã‚’è¡Œã†ã¨åˆå›è¨ˆç®—ãŒèµ°ã‚Šã¾ã™ã€‚")
            if st.button("ä»Šã™ãå¼·åˆ¶é›†è¨ˆ (å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)"):
                update_analytics_background()
                st.success("ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰é›†è¨ˆã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        else:
            # --- Section 1: KPI Scorecard ---
            st.markdown("#### 1. The Head-Up Display")
            kpi = analytics_data.get('kpi', {})
            c_k1, c_k2, c_k3 = st.columns(3)
            
            # Early Bonus Rate
            ebr = kpi.get('early_bonus_rate', 0)
            c_k1.metric(
                label="ğŸ† Early Bonus Rate",
                value=f"{ebr}%",
                delta="Target: 80%",
                delta_color="normal" if ebr >= 80 else "inverse"
            )
            # RPD
            rpd = kpi.get('rpd', 0)
            c_k2.metric(
                label="ğŸ’° RPD (è³‡ç”£å›è»¢é€Ÿåº¦)",
                value=f"Â¥{rpd}/day",
                help="1æ—¥ã‚ãŸã‚Šä½•å††ã®ä¾¡å€¤ã‚’ç”Ÿã‚“ã§ã„ã‚‹ã‹"
            )
            # Avg Holding Days
            ahd = kpi.get('avg_holding_days', 0)
            c_k3.metric(
                label="âš¡ Avg. Holding Days",
                value=f"{ahd} days",
                delta="Limit: 3.0 days",
                delta_color="inverse"
            )
            st.divider()

            # --- Section 2: Histogram ---
            st.markdown("#### 2. Cycle Histogram (åœ¨åº«ã‚µã‚¤ã‚¯ãƒ«åˆ†å¸ƒ)")
            hist_d = analytics_data.get('histogram', {})
            if hist_d:
                hist_df = pd.DataFrame(list(hist_d.items()), columns=['days_str', 'count'])
                hist_df['days'] = pd.to_numeric(hist_df['days_str'])
                hist_df['zone'] = hist_df['days'].apply(
                    lambda x: 'ğŸŸ¢ Zone A (Ideal)' if x <= 3 else ('ğŸŸ¡ Zone B (Normal)' if x <= 22 else 'ğŸ”´ Zone C (Danger)')
                )
                
                chart_hist = alt.Chart(hist_df).mark_bar().encode(
                    x=alt.X('days', title='ä¿æœ‰æ—¥æ•°'),
                    y=alt.Y('count', title='æœ¬æ•°'),
                    color=alt.Color('zone', scale=alt.Scale(
                        domain=['ğŸŸ¢ Zone A (Ideal)', 'ğŸŸ¡ Zone B (Normal)', 'ğŸ”´ Zone C (Danger)'],
                        range=['#4caf50', '#ffeb3b', '#f44336']
                    )),
                    tooltip=['days', 'count', 'zone']
                ).properties(height=250)
                st.altair_chart(chart_hist, use_container_width=True)
            
            # --- Section 3: Heatmap ---
            st.markdown("#### 3. Activity Heatmap (æ›œæ—¥åˆ¥æ´»å‹•é‡)")
            hm_d = analytics_data.get('heatmap', [])
            if hm_d:
                hm_df = pd.DataFrame(hm_d)
                days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                
                chart_heat = alt.Chart(hm_df).mark_rect().encode(
                    x=alt.X('time_zone', title='åŒºåˆ† (ç¾åœ¨Dayã®ã¿)'),
                    y=alt.Y('weekday', sort=days_order, title='æ›œæ—¥'),
                    color=alt.Color('count', title='å®Œäº†æ•°', scale=alt.Scale(scheme='orangered')),
                    tooltip=['weekday', 'count']
                ).properties(height=300)
                st.altair_chart(chart_heat, use_container_width=True)
                st.caption("â€»æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€æ›œæ—¥ã”ã¨ã®ç·é‡ã§è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")

            # --- Section 4: Trend ---
            st.markdown("#### 4. Efficiency Trend (é€±æ¬¡ å¹³å‡ä¿æœ‰æ—¥æ•°)")
            tr_d = analytics_data.get('trend', [])
            if tr_d:
                tr_df = pd.DataFrame(tr_d)
                chart_trend = alt.Chart(tr_df).mark_line(point=True).encode(
                    x=alt.X('week', title='é€±'),
                    y=alt.Y('avg_days', title='å¹³å‡ä¿æœ‰æ—¥æ•°', scale=alt.Scale(zero=False)),
                    tooltip=['week', 'avg_days']
                ).properties(height=250)
                st.altair_chart(chart_trend, use_container_width=True)

            st.caption(f"Last Updated: {analytics_data.get('updated_at', '-')}")

if __name__ == '__main__':
    main()
