import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import datetime
import re
import altair as alt
import textwrap
import json

# --- å®šæ•°ãƒ»è¨­å®š ---
PENALTY_LIMIT_DAYS = 28
NEW_SHEET_NAME = 'database' 
EXPECTED_HEADERS = ['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'ä¿æœ‰é–‹å§‹æ—¥', 'å®Œäº†æ—¥', 'ã‚¨ãƒªã‚¢', 'é‡‘é¡', 'å‚™è€ƒ']

# --- ã‚¨ãƒªã‚¢å®šç¾© ---
ZONE_OPTIONS = [
    "D: ãã®ä»– (èˆ¹æ©‹ãªã©)", 
    "A: æ±äº¬23åŒº", 
    "B: æ±äº¬éƒ½ä¸‹", 
    "C: æŒ‡å®šéƒ½å¸‚(æ¨ªæµœç­‰)"
]
ZONES = {
    "D: ãã®ä»– (èˆ¹æ©‹ãªã©)": 70,
    "A: æ±äº¬23åŒº": 55,
    "B: æ±äº¬éƒ½ä¸‹": 65,
    "C: æŒ‡å®šéƒ½å¸‚(æ¨ªæµœç­‰)": 60,
}

# --- GCPè¨­å®š ---
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

def get_connection():
    if "gcp_service_account" not in st.secrets:
        st.error("Secretsã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None
    creds_dict = st.secrets["gcp_service_account"]
    creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
    client = gspread.authorize(creds)
    return client

def get_today_jst():
    now = datetime.datetime.now() + datetime.timedelta(hours=9)
    return now.date()

def sanitize_for_json(val):
    if pd.isna(val): return ""
    if isinstance(val, (datetime.date, datetime.datetime)):
        return val.strftime('%Y-%m-%d')
    if hasattr(val, 'item'): return val.item()
    return str(val)

# --- ãƒ†ã‚­ã‚¹ãƒˆè§£æ ---
def extract_serials_with_date(text, default_date):
    results = []
    default_date_str = default_date.strftime('%Y-%m-%d')
    text = text.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789'))
    
    date_pattern = re.compile(r'(\d{4})[-/.](\d{2})[-/.](\d{2})')
    serial_pattern = re.compile(r'\b(\d{8})\b')

    lines = [line.strip() for line in text.split('\n') if line.strip()]
    
    for i, line in enumerate(lines):
        serials_in_line = serial_pattern.findall(line)
        if not serials_in_line: continue
        
        search_window = lines[max(0, i-2) : min(len(lines), i+3)]
        found_date = default_date_str
        for check_line in search_window:
            d_match = date_pattern.search(check_line)
            if d_match:
                found_date = f"{d_match.group(1)}-{d_match.group(2)}-{d_match.group(3)}"
                break
        
        for s in serials_in_line:
            results.append((s, found_date))
            
    if not results:
        all_serials = serial_pattern.findall(text)
        all_dates = date_pattern.findall(text)
        if all_serials:
            backup_date = f"{all_dates[0][0]}-{all_dates[0][1]}-{all_dates[0][2]}" if all_dates else default_date_str
            for s in all_serials: results.append((s, backup_date))

    unique_map = {r[0]: r[1] for r in results}
    return list(unique_map.items())

def extract_serials_only(text):
    text = text.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789'))
    return list(set(re.findall(r'\b\d{8}\b', text)))

# --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
def get_database():
    client = get_connection()
    if not client: return pd.DataFrame()
    try:
        try:
            sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
        except:
            wb = client.open('battery_db')
            sheet = wb.add_worksheet(title=NEW_SHEET_NAME, rows=1000, cols=10)
            sheet.append_row(EXPECTED_HEADERS)

        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        
        if df.empty: return pd.DataFrame(columns=EXPECTED_HEADERS)
        
        df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'] = df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].astype(str)
        if 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in df.columns:
            df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] = df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'].astype(str).str.strip()
        else:
            sheet.insert_row(EXPECTED_HEADERS, index=1)
            return pd.DataFrame(columns=EXPECTED_HEADERS)

        df['é‡‘é¡'] = pd.to_numeric(df['é‡‘é¡'], errors='coerce').fillna(0).astype(int)
        for col in ['ä¿æœ‰é–‹å§‹æ—¥', 'å®Œäº†æ—¥']:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
        return df
    except Exception as e:
        st.error(f"èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def get_active_inventory(df_all):
    if df_all.empty or 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' not in df_all.columns: return pd.DataFrame()
    df = df_all[df_all['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'åœ¨åº«'].copy()
    if not df.empty:
        df['rev_serial'] = df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].apply(lambda x: x[::-1])
        df_sorted = df.sort_values(by=['ä¿æœ‰é–‹å§‹æ—¥', 'rev_serial'], ascending=[True, True])
        return df_sorted.drop(columns=['rev_serial'])
    return df

def get_vol_bonus(count):
    if count >= 150: return 20
    elif count >= 100: return 15
    elif count >= 50: return 10
    elif count >= 20: return 5
    else: return 0

# --- æ›¸ãè¾¼ã¿ãƒ»è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ ---

def recalc_weekly_revenue(sheet, today_date):
    """
    ä»Šé€±ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å†è¨ˆç®—ã—ã€æœ€æ–°ã®ãƒœãƒ¼ãƒŠã‚¹å˜ä¾¡ã§é‡‘é¡ã‚’ä¸Šæ›¸ãã™ã‚‹
    """
    all_records = sheet.get_all_records()
    headers = sheet.row_values(1)
    
    try:
        col_price = headers.index('é‡‘é¡') + 1
    except: return 0

    # ä»Šé€±ã®ç¯„å›²ã‚’ç‰¹å®š (æœˆæ›œã€œæ—¥æ›œ)
    start_of_week = today_date - datetime.timedelta(days=today_date.weekday())
    end_of_week = start_of_week + datetime.timedelta(days=6)

    # 1. ä»Šé€±ã®æœ¬æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    weekly_indices = []
    
    for i, row in enumerate(all_records):
        st_val = str(row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')).strip()
        comp_date_str = str(row.get('å®Œäº†æ—¥', ''))
        
        if st_val == 'è£œå……æ¸ˆ' and comp_date_str:
            try:
                comp_date = datetime.datetime.strptime(comp_date_str, '%Y-%m-%d').date()
                if start_of_week <= comp_date <= end_of_week:
                    weekly_indices.append(i)
            except: pass

    week_count = len(weekly_indices)
    current_bonus = get_vol_bonus(week_count)
    
    # 2. å˜ä¾¡ã‚’å†è¨ˆç®—ã—ã¦æ›´æ–°
    cells_to_update = []
    updated_count = 0
    
    for idx in weekly_indices:
        row = all_records[idx]
        
        # ã‚¨ãƒªã‚¢å˜ä¾¡
        zone_name = str(row.get('ã‚¨ãƒªã‚¢', ''))
        base_price = ZONES.get(zone_name, 70) # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ70
        
        # æ—©æœŸãƒœãƒ¼ãƒŠã‚¹åˆ¤å®š
        start_d_str = str(row.get('ä¿æœ‰é–‹å§‹æ—¥', ''))
        end_d_str = str(row.get('å®Œäº†æ—¥', ''))
        early_bonus = 0
        try:
            s_date = datetime.datetime.strptime(start_d_str, '%Y-%m-%d').date()
            e_date = datetime.datetime.strptime(end_d_str, '%Y-%m-%d').date()
            if (e_date - s_date).days <= 3:
                early_bonus = 10
        except: pass
        
        # æ–°ã—ã„å˜ä¾¡
        new_total_price = base_price + current_bonus + early_bonus
        
        # ç¾åœ¨ã®å€¤ã¨é•ãˆã°æ›´æ–°ãƒªã‚¹ãƒˆã¸
        current_recorded_price = row.get('é‡‘é¡', 0)
        if current_recorded_price != new_total_price:
            cells_to_update.append(gspread.Cell(idx + 2, col_price, new_total_price))
            updated_count += 1

    if cells_to_update:
        sheet.update_cells(cells_to_update)
        
    return updated_count

def register_new_inventory(data_list):
    client = get_connection()
    sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
    all_records = sheet.get_all_records()
    df = pd.DataFrame(all_records)
    
    current_active = set()
    if not df.empty and 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in df.columns:
        active_df = df[df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'].astype(str).str.strip() == 'åœ¨åº«']
        current_active = set(active_df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].astype(str).tolist())
    
    headers = sheet.row_values(1)
    if not headers: sheet.append_row(EXPECTED_HEADERS)

    rows = []
    skipped = 0
    for s, d in data_list:
        s_str = str(s)
        if s_str in current_active:
            skipped += 1
            continue
        row = [sanitize_for_json(s_str), "åœ¨åº«", sanitize_for_json(d), "", "", "", ""]
        rows.append(row)
    
    if rows:
        try: sheet.append_rows(rows)
        except Exception as e:
            st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return 0, 0
    return len(rows), skipped

def update_status_bulk(target_serials, new_status, complete_date=None, zone="", price=0, memo=""):
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–° + é€±æ¬¡ãƒœãƒ¼ãƒŠã‚¹å†è¨ˆç®—"""
    client = get_connection()
    sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
    all_records = sheet.get_all_records()
    headers = sheet.row_values(1)
    
    try:
        col_status = headers.index('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹') + 1
        col_end = headers.index('å®Œäº†æ—¥') + 1
        col_zone = headers.index('ã‚¨ãƒªã‚¢') + 1
        col_price = headers.index('é‡‘é¡') + 1
        col_memo = headers.index('å‚™è€ƒ') + 1
    except: return 0

    cells = []
    updated = 0
    target_set = set(str(s) for s in target_serials)
    
    comp_str = sanitize_for_json(complete_date)
    # ã“ã“ã§ã®priceã¯æš«å®šå€¤ã€‚ç›´å¾Œã«recalc_weekly_revenueã§ä¸Šæ›¸ãã•ã‚Œã‚‹
    safe_price = int(price)

    for i, row in enumerate(all_records):
        s = str(row.get('ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼', ''))
        st_val = str(row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')).strip()
        if st_val == 'åœ¨åº«' and s in target_set:
            r = i + 2
            cells.append(gspread.Cell(r, col_status, new_status))
            cells.append(gspread.Cell(r, col_end, comp_str))
            cells.append(gspread.Cell(r, col_zone, zone))
            cells.append(gspread.Cell(r, col_price, safe_price))
            if memo: cells.append(gspread.Cell(r, col_memo, memo))
            updated += 1
            
    if cells:
        try: sheet.update_cells(cells)
        except Exception as e:
            st.error(f"æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            return 0
            
    # â˜…ã“ã“ã§ä»Šé€±åˆ†ã®é‡‘é¡ã‚’å†è¨ˆç®—ã—ã¦ä¸€æ–‰æ›´æ–°
    if updated > 0 and new_status == 'è£œå……æ¸ˆ' and complete_date:
        recalc_weekly_revenue(sheet, complete_date)

    return updated

def update_dates_bulk(updates_list):
    client = get_connection()
    sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
    all_records = sheet.get_all_records()
    headers = sheet.row_values(1)
    if 'ä¿æœ‰é–‹å§‹æ—¥' not in headers: return 0
    col_start = headers.index('ä¿æœ‰é–‹å§‹æ—¥') + 1
    
    cells = []
    updates_map = {str(s): sanitize_for_json(d) for s, d in updates_list}
    
    for i, row in enumerate(all_records):
        s = str(row.get('ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼', ''))
        st_val = str(row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')).strip()
        if st_val == 'åœ¨åº«' and s in updates_map:
            r = i + 2
            cells.append(gspread.Cell(r, col_start, updates_map[s]))
            
    if cells:
        try: sheet.update_cells(cells)
        except: return 0
    return len(cells)

# --- UIãƒ‘ãƒ¼ãƒ„ ---
def create_card(row, today):
    start_date = row['ä¿æœ‰é–‹å§‹æ—¥']
    if pd.isnull(start_date):
        s_str, days, p_days = "-", 0, 99
    else:
        s_str = start_date.strftime('%m/%d')
        days = (today - start_date).days
        p_days = PENALTY_LIMIT_DAYS - days
    
    sn = row['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼']
    last4 = sn[-4:]
    
    if p_days <= 5: 
        c, bg, st_t, bd = "#c62828", "#fff5f5", f"ğŸ”¥ è¦è¿”å´ (æ®‹{p_days}æ—¥)", "#e57373"
    elif days <= 3: 
        c, bg, st_t, bd = "#2e7d32", "#f1f8e9", "ğŸ’ Bonus", "#81c784"
    else: 
        c, bg, st_t, bd = "#616161", "#ffffff", f"ğŸ¢ é€šå¸¸ (æ®‹{p_days}æ—¥)", "#bdbdbd"
        
    return textwrap.dedent(f"""
    <div style="background:{bg}; border-radius:8px; border-left:8px solid {bd}; padding:12px; margin-bottom:10px; box-shadow:0 2px 5px rgba(0,0,0,0.1);">
        <div style="display:flex; justify-content:space-between; font-weight:bold; font-size:12px; color:{c};">
            <div>{st_t}</div><div>{s_str}ã€œ</div>
        </div>
        <div style="font-size:34px; font-weight:900; color:#212121;">{last4}</div>
        <div style="text-align:right; font-size:10px; color:#999; font-family:monospace;">{sn}</div>
    </div>
    """)

# --- ãƒ¡ã‚¤ãƒ³ ---
def main():
    st.set_page_config(page_title="Battery Manager V10", page_icon="âš¡", layout="wide")
    st.markdown("<style>.stSlider{padding-top:1rem;}</style>", unsafe_allow_html=True)
    today = get_today_jst()

    if 'stocktake_buffer' not in st.session_state: st.session_state['stocktake_buffer'] = []
    if 'parsed_data' not in st.session_state: st.session_state['parsed_data'] = None

    df_all = get_database()
    df_inv = get_active_inventory(df_all)
    df_hist = df_all[df_all['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] != 'åœ¨åº«'] if not df_all.empty else pd.DataFrame()

    week_earnings = 0
    week_count = 0
    if not df_hist.empty:
        start_of_week = today - datetime.timedelta(days=today.weekday())
        w_df = df_hist[(df_hist['å®Œäº†æ—¥'] >= start_of_week) & (df_hist['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'è£œå……æ¸ˆ')]
        week_count = len(w_df)
        week_earnings = int(w_df['é‡‘é¡'].sum())
    cur_bonus = get_vol_bonus(week_count)

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ  ãƒ›ãƒ¼ãƒ ", "ğŸ” æ¤œç´¢", "ğŸ“¦ åœ¨åº«", "ğŸ’° åç›Š", "ğŸ“ æ£šå¸"])

    # 1. ãƒ›ãƒ¼ãƒ 
    with tab1:
        c1, c2, c3 = st.columns(3)
        c1.metric("å ±é…¬", f"Â¥ {week_earnings:,}")
        c2.metric("æœ¬æ•°", f"{week_count} æœ¬")
        c3.metric("ç¾åœ¨ãƒœãƒŠ", f"+{cur_bonus}å††/æœ¬")
        st.divider()

        mode = st.radio("ãƒ¢ãƒ¼ãƒ‰", ["å–å‡º (ç™»éŒ²)", "è£œå…… (ç¢ºå®š)"], horizontal=True)
        
        if mode == "å–å‡º (ç™»éŒ²)":
            txt = st.text_area("SpotJobsãƒªã‚¹ãƒˆè²¼ä»˜", height=100)
            date_in = st.date_input("åŸºæº–æ—¥", value=today)
            if st.button("èª­è¾¼", icon=":material/search:"):
                if txt:
                    parsed = extract_serials_with_date(txt, date_in)
                    st.session_state['parsed_data'] = parsed
                    st.success(f"{len(parsed)} ä»¶ èª­è¾¼")
            
            if st.session_state['parsed_data']:
                st.dataframe(pd.DataFrame(st.session_state['parsed_data'], columns=["SN","æ—¥ä»˜"]), hide_index=True)
                if st.button("ç™»éŒ²å®Ÿè¡Œ", type="primary"):
                    cnt, skip = register_new_inventory(st.session_state['parsed_data'])
                    if cnt > 0:
                        st.success(f"âœ… {cnt}ä»¶ ç™»éŒ²å®Œäº†")
                        st.session_state['parsed_data'] = None
                        import time
                        time.sleep(1)
                        st.rerun()
                    else: st.warning("ç™»éŒ²ãªã— (ã™ã¹ã¦é‡è¤‡)")

        else: 
            col_d, col_z = st.columns([1,1])
            date_done = col_d.date_input("è£œå……æ—¥", value=today)
            zone = col_z.selectbox("ã‚¨ãƒªã‚¢", ZONE_OPTIONS)
            txt = st.text_area("è£œå……ãƒªã‚¹ãƒˆè²¼ä»˜", height=100)
            if txt:
                sns = extract_serials_only(txt)
                if sns:
                    # äºˆæ¸¬è¡¨ç¤º (ã“ã“ã§ã®è¡¨ç¤ºã¯å‚è€ƒå€¤ã€ç¢ºå®šæ™‚ã«å…¨ä»¶å†è¨ˆç®—ã•ã‚Œã‚‹)
                    base = ZONES[zone]
                    new_count = week_count + len(sns)
                    new_bonus = get_vol_bonus(new_count)
                    st.info(f"{len(sns)}ä»¶æ¤œå‡º / ç¢ºå®šå¾Œã®å…¨ä»¶ãƒœãƒ¼ãƒŠã‚¹: +{new_bonus}å†† (ç·æ•°{new_count}æœ¬)")
                    
                    if st.button("è£œå……ç¢ºå®š (é¡åŠè¨ˆç®—)", type="primary"):
                        cnt = update_status_bulk(sns, "è£œå……æ¸ˆ", date_done, zone, base)
                        st.success(f"{cnt}ä»¶ æ›´æ–° & ä»Šé€±åˆ†ã®å˜ä¾¡ã‚’å†è¨ˆç®—ã—ã¾ã—ãŸ")
                        import time
                        time.sleep(1)
                        st.rerun()

        st.divider()
        if not df_inv.empty:
            cols = st.columns(4)
            for i, (_, row) in enumerate(df_inv.head(4).iterrows()):
                cols[i].markdown(create_card(row, today), unsafe_allow_html=True)

    # 2. æ¤œç´¢
    with tab2:
        sn_in = st.number_input("SNä¸‹4æ¡", 0, 9999, 0)
        if sn_in > 0 and not df_all.empty:
            hits = df_all[df_all['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].str.endswith(str(sn_in))]
            if not hits.empty:
                st.success(f"{len(hits)}ä»¶ ãƒ’ãƒƒãƒˆ")
                for _, row in hits.iterrows():
                    st.info(f"çŠ¶æ…‹: {row['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹']} / é–‹å§‹: {row['ä¿æœ‰é–‹å§‹æ—¥']} / å®Œäº†: {row['å®Œäº†æ—¥']}")
            else: st.warning("ãªã—")

    # 3. åœ¨åº«
    with tab3:
        st.metric("åœ¨åº«æ•°", f"{len(df_inv)}")
        st.dataframe(df_inv, use_container_width=True)

    # 4. åç›Š
    with tab4:
        st.metric("ä»Šé€±", f"Â¥{week_earnings:,}")
        if not df_hist.empty:
            df_g = df_hist[df_hist['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹']=='è£œå……æ¸ˆ']
            st.dataframe(df_g.sort_values('å®Œäº†æ—¥', ascending=False), use_container_width=True)

    # 5. æ£šå¸
    with tab5:
        st.subheader("åœ¨åº«æ£šå¸ã—")
        cur = st.session_state['stocktake_buffer']
        
        c1, c2 = st.columns([1,1])
        with c1:
            txt_stock = st.text_area("ãƒªã‚¹ãƒˆè¿½åŠ ")
            if st.button("ãƒªã‚¹ãƒˆã«è¿½åŠ "):
                if txt_stock:
                    add = extract_serials_with_date(txt_stock, today)
                    st.session_state['stocktake_buffer'].extend(add)
                    uniq = {s:d for s,d in st.session_state['stocktake_buffer']}
                    st.session_state['stocktake_buffer'] = list(uniq.items())
                    st.rerun()
            if st.button("ã‚¯ãƒªã‚¢"):
                st.session_state['stocktake_buffer'] = []
                st.rerun()
        
        with c2:
            st.caption(f"èª­è¾¼: {len(cur)}ä»¶")
            if cur: st.dataframe(pd.DataFrame(cur, columns=["SN","æ—¥ä»˜"]), height=150, hide_index=True)

        st.divider()
        c_act1, c_act2 = st.columns(2)
        with c_act1:
            if st.button("ç…§åˆï¼†ç™»éŒ²ãƒ»æ›´æ–°", type="primary", use_container_width=True):
                if cur:
                    s_map = {s:d for s,d in cur}
                    db_map = {}
                    if not df_inv.empty:
                        db_map = dict(zip(df_inv['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'], df_inv['ä¿æœ‰é–‹å§‹æ—¥']))
                    
                    def fdate(d): return d.strftime('%Y-%m-%d') if pd.notnull(d) else ""
                    
                    missing_db = []
                    date_mis = []
                    for s, d in s_map.items():
                        if s not in db_map: missing_db.append((s, d))
                        elif fdate(db_map[s]) != d: date_mis.append((s, d))
                    
                    msg = []
                    if missing_db:
                        cnt, _ = register_new_inventory(missing_db)
                        msg.append(f"æ–°è¦: {cnt}ä»¶")
                    if date_mis:
                        cnt = update_dates_bulk(date_mis)
                        msg.append(f"æ—¥ä»˜æ›´æ–°: {cnt}ä»¶")
                    
                    if msg: st.success(" / ".join(msg))
                    else: st.info("å¤‰æ›´ãªã—")
                    
                    import time
                    time.sleep(1)
                    st.rerun()
                else: st.warning("ãƒªã‚¹ãƒˆãªã—")

        with c_act2:
            if st.button("å¼·åˆ¶å…¨ä»¶ç™»éŒ² (æ•‘æ¸ˆ)", use_container_width=True):
                if cur:
                    cnt, skip = register_new_inventory(cur)
                    st.success(f"{cnt}ä»¶ å¼·åˆ¶ç™»éŒ²")
                    import time
                    time.sleep(1)
                    st.rerun()

if __name__ == '__main__':
    main()
