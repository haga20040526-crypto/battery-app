import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import datetime
import re
import altair as alt
import uuid
import time
import json
import threading
import os

# --- å®šæ•°ãƒ»è¨­å®š ---
PENALTY_LIMIT_DAYS = 28
NEW_SHEET_NAME = 'database' 
# ã‚¸ãƒ§ãƒ–IDåˆ—ã‚’å«ã‚€ãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©
EXPECTED_HEADERS = ['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'ä¿æœ‰é–‹å§‹æ—¥', 'å®Œäº†æ—¥', 'ã‚¨ãƒªã‚¢', 'é‡‘é¡', 'å‚™è€ƒ', 'ã‚¸ãƒ§ãƒ–ID']
ANALYTICS_CACHE_FILE = 'analytics_cache.json'

# --- ã‚¨ãƒªã‚¢å®šç¾© ---
ZONE_OPTIONS = [
    "D: ãã®ä»– (èˆ¹æ©‹ãªã©)", 
    "A: æ±äº¬23åŒº", 
    "B: æ±äº¬éƒ½ä¸‹", 
    "C: æŒ‡å®šéƒ½å¸‚(æ¨ªæµœç­‰)"
]
ZONES = {
    "D: ãã®ä»– (èˆ¹æ©‹ãªã©)": 70,
    "A: æ±äº¬23åŒº": 55,
    "B: æ±äº¬éƒ½ä¸‹": 65,
    "C: æŒ‡å®šéƒ½å¸‚(æ¨ªæµœç­‰)": 60,
}

# --- GCPè¨­å®š ---
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

def get_connection():
    if "gcp_service_account" not in st.secrets:
        st.error("ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: Secretsã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None
    creds_dict = st.secrets["gcp_service_account"]
    creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
    client = gspread.authorize(creds)
    return client

def get_today_jst():
    now = datetime.datetime.now() + datetime.timedelta(hours=9)
    return now.date()

def sanitize_for_json(val):
    if pd.isna(val): return ""
    if isinstance(val, (datetime.date, datetime.datetime)):
        return val.strftime('%Y-%m-%d')
    if hasattr(val, 'item'): return val.item()
    return str(val)

# --- ãƒ†ã‚­ã‚¹ãƒˆè§£æ ---
def extract_serials_with_date(text, default_date):
    results = []
    default_date_str = default_date.strftime('%Y-%m-%d')
    if text:
        text = text.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789'))
    else: return []
    
    date_pattern = re.compile(r'(\d{4})[-/.](\d{2})[-/.](\d{2})')
    serial_pattern = re.compile(r'\b(\d{8})\b')

    lines = [line.strip() for line in text.split('\n') if line.strip()]
    
    for i, line in enumerate(lines):
        serials_in_line = serial_pattern.findall(line)
        if not serials_in_line: continue
        
        search_window = lines[i : min(len(lines), i+4)]
        found_date = default_date_str
        for check_line in search_window:
            d_match = date_pattern.search(check_line)
            if d_match:
                found_date = f"{d_match.group(1)}-{d_match.group(2)}-{d_match.group(3)}"
                break
        
        for s in serials_in_line:
            results.append((s, found_date))
            
    if not results:
        all_serials = serial_pattern.findall(text)
        all_dates = date_pattern.findall(text)
        if all_serials:
            backup_date = f"{all_dates[0][0]}-{all_dates[0][1]}-{all_dates[0][2]}" if all_dates else default_date_str
            for s in all_serials: results.append((s, backup_date))

    unique_map = {r[0]: r[1] for r in results}
    return list(unique_map.items())

def extract_serials_only(text):
    if not text: return []
    text = text.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789'))
    return list(set(re.findall(r'\b\d{8}\b', text)))

# --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
def get_database():
    client = get_connection()
    if not client: return pd.DataFrame()
    try:
        try:
            sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
        except:
            wb = client.open('battery_db')
            sheet = wb.add_worksheet(title=NEW_SHEET_NAME, rows=1000, cols=10)
            sheet.append_row(EXPECTED_HEADERS)

        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        
        if df.empty: return pd.DataFrame(columns=EXPECTED_HEADERS)
        
        # ã‚«ãƒ©ãƒ ä¸è¶³ã®è£œæ­£
        current_cols = df.columns.tolist()
        if 'ã‚¸ãƒ§ãƒ–ID' not in current_cols:
            sheet.update_cell(1, len(current_cols) + 1, 'ã‚¸ãƒ§ãƒ–ID')
            df['ã‚¸ãƒ§ãƒ–ID'] = ""

        df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'] = df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].astype(str)
        if 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in df.columns:
            df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] = df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'].astype(str).str.strip()
        
        df['é‡‘é¡'] = pd.to_numeric(df['é‡‘é¡'], errors='coerce').fillna(0).astype(int)
        for col in ['ä¿æœ‰é–‹å§‹æ—¥', 'å®Œäº†æ—¥']:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
        return df
    except: return pd.DataFrame()

def get_active_inventory(df_all):
    if df_all.empty or 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' not in df_all.columns: return pd.DataFrame()
    df = df_all[df_all['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'åœ¨åº«'].copy()
    if not df.empty:
        df = df.sort_values(by=['ä¿æœ‰é–‹å§‹æ—¥'], ascending=[True])
        return df
    return df

def get_vol_bonus(count):
    if count >= 150: return 20
    elif count >= 100: return 15
    elif count >= 50: return 10
    elif count >= 20: return 5
    else: return 0

# --- åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Analytics Logic V1.4) ---

def calculate_kpi_for_period(df_subset):
    if len(df_subset) == 0:
        return {"ebr": 0, "rpd": 0, "ahd": 0, "count": 0, "revenue": 0, "avg_price": 0}
    
    early_count = len(df_subset[df_subset['holding_days'] <= 3])
    ebr = (early_count / len(df_subset)) * 100
    
    total_rev = df_subset['é‡‘é¡'].sum()
    total_hold_days = df_subset['holding_days'].sum()
    rpd = total_rev / total_hold_days if total_hold_days > 0 else 0
    ahd = df_subset['holding_days'].mean()
    avg_price = df_subset['é‡‘é¡'].mean()

    return {
        "ebr": ebr, "rpd": rpd, "ahd": ahd, 
        "count": len(df_subset), "revenue": total_rev, "avg_price": avg_price
    }

def calculate_analytics_logic(df):
    if df.empty: return {}
    df['completed_at'] = pd.to_datetime(df['å®Œäº†æ—¥'], errors='coerce')
    df['acquired_at'] = pd.to_datetime(df['ä¿æœ‰é–‹å§‹æ—¥'], errors='coerce')
    
    completed_df = df[df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'è£œå……æ¸ˆ'].copy()
    completed_df = completed_df.dropna(subset=['completed_at', 'acquired_at'])
    completed_df['holding_days'] = (completed_df['completed_at'] - completed_df['acquired_at']).dt.days
    
    today = datetime.datetime.now()
    current_start = today - datetime.timedelta(days=7)
    previous_start = today - datetime.timedelta(days=14)
    
    current_df = completed_df[completed_df['completed_at'] >= current_start]
    prev_df = completed_df[(completed_df['completed_at'] >= previous_start) & (completed_df['completed_at'] < current_start)]
    
    cur_metrics = calculate_kpi_for_period(current_df)
    prev_metrics = calculate_kpi_for_period(prev_df)
    
    input_df = df[df['acquired_at'] >= current_start]
    input_count = len(input_df)
    output_count = cur_metrics['count']
    io_balance = (input_count / output_count) if output_count > 0 else 0
    
    month_start = today - datetime.timedelta(days=30)
    month_df = completed_df[completed_df['completed_at'] >= month_start].copy()
    raw_holding_days = month_df['holding_days'].tolist()

    month_df['weekday'] = month_df['completed_at'].dt.day_name()
    heatmap_series = month_df.groupby('weekday').size()
    heatmap_data = [{'weekday': wd, 'count': int(count)} for wd, count in heatmap_series.items()]

    three_months_ago = today - datetime.timedelta(days=90)
    trend_df = completed_df[completed_df['completed_at'] >= three_months_ago].copy()
    trend_df['week'] = trend_df['completed_at'].dt.to_period('W').astype(str)
    trend_series = trend_df.groupby('week')['holding_days'].mean()
    trend_data = [{'week': w, 'avg_days': round(d, 2)} for w, d in trend_series.items()]

    return {
        "scorecard": {"current": cur_metrics, "previous": prev_metrics},
        "tactical": {"io_balance": round(io_balance, 2), "input_count": input_count, "output_count": output_count},
        "histogram_raw": raw_holding_days,
        "heatmap": heatmap_data,
        "trend": trend_data,
        "updated_at": today.strftime('%Y-%m-%d %H:%M:%S')
    }

def update_analytics_background():
    def task():
        try:
            df = get_database()
            if df.empty: return
            data = calculate_analytics_logic(df)
            with open(ANALYTICS_CACHE_FILE, 'w') as f:
                json.dump(data, f)
        except Exception as e:
            print(f"Background update failed: {e}")
    thread = threading.Thread(target=task)
    thread.start()

def load_analytics_cache():
    if not os.path.exists(ANALYTICS_CACHE_FILE):
        return None
    try:
        with open(ANALYTICS_CACHE_FILE, 'r') as f:
            return json.load(f)
    except:
        return None

# --- æ›¸ãè¾¼ã¿ãƒ»è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ ---

def register_new_inventory(data_list):
    client = get_connection()
    sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
    all_records = sheet.get_all_records()
    df = pd.DataFrame(all_records)
    
    current_active_serials = set()
    if not df.empty and 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in df.columns:
        active_df = df[df['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'].astype(str).str.strip().isin(['åœ¨åº«', 'å‡ºåº«ä¸­'])]
        current_active_serials = set(active_df['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].astype(str).tolist())
    
    headers = sheet.row_values(1)
    if not headers: sheet.append_row(EXPECTED_HEADERS)

    rows = []
    skipped = 0
    for s, d in data_list:
        s_str = str(s)
        if s_str in current_active_serials:
            skipped += 1
            continue
        row = [sanitize_for_json(s_str), "åœ¨åº«", sanitize_for_json(d), "", "", "", "", ""]
        rows.append(row)
    
    if rows:
        try: 
            sheet.append_rows(rows)
            update_analytics_background()
        except: return 0, 0
    return len(rows), skipped

def register_past_bulk(date_obj, count, total_amount, zone, memo="", job_id=""):
    client = get_connection()
    sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
    headers = sheet.row_values(1)
    if not headers: sheet.append_row(EXPECTED_HEADERS)
    if count <= 0: return 0
    
    base_amount = total_amount // count
    remainder = total_amount % count
    date_str = date_obj.strftime('%Y-%m-%d')
    rows = []
    for i in range(count):
        dummy_sn = f"OLD-{date_str.replace('-','')}-{uuid.uuid4().hex[:6]}"
        amount = base_amount + (1 if i < remainder else 0)
        row = [dummy_sn, "è£œå……æ¸ˆ", "", date_str, zone, amount, memo, job_id]
        rows.append(row)
    if rows: 
        sheet.append_rows(rows)
        update_analytics_background()

    return len(rows)

def recalc_weekly_revenue(sheet, today_date):
    all_records = sheet.get_all_records()
    headers = sheet.row_values(1)
    try: col_price = headers.index('é‡‘é¡') + 1
    except: return 0

    start_of_week = today_date - datetime.timedelta(days=today_date.weekday())
    end_of_week = start_of_week + datetime.timedelta(days=6)

    weekly_indices = []
    for i, row in enumerate(all_records):
        st_val = str(row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')).strip()
        comp_date_str = str(row.get('å®Œäº†æ—¥', ''))
        memo = str(row.get('å‚™è€ƒ', ''))
        
        if st_val == 'è£œå……æ¸ˆ' and comp_date_str and 'ãƒœãƒ¼ãƒŠã‚¹' not in memo:
            try:
                comp_date = datetime.datetime.strptime(comp_date_str, '%Y-%m-%d').date()
                if start_of_week <= comp_date <= end_of_week:
                    weekly_indices.append(i)
            except: pass

    week_count = len(weekly_indices)
    current_bonus = get_vol_bonus(week_count)
    
    cells_to_update = []
    for idx in weekly_indices:
        row = all_records[idx]
        zone_name = str(row.get('ã‚¨ãƒªã‚¢', ''))
        base_price = ZONES.get(zone_name, 70)
        start_d_str = str(row.get('ä¿æœ‰é–‹å§‹æ—¥', ''))
        end_d_str = str(row.get('å®Œäº†æ—¥', ''))
        early_bonus = 0
        try:
            s_date = datetime.datetime.strptime(start_d_str, '%Y-%m-%d').date()
            e_date = datetime.datetime.strptime(end_d_str, '%Y-%m-%d').date()
            if (e_date - s_date).days <= 3: early_bonus = 10
        except: pass
        
        new_total_price = base_price + current_bonus + early_bonus
        if row.get('é‡‘é¡', 0) != new_total_price:
            cells_to_update.append(gspread.Cell(idx + 2, col_price, new_total_price))

    if cells_to_update:
        try: sheet.update_cells(cells_to_update)
        except: pass
    return len(cells_to_update)

def update_status_bulk(target_serials, new_status, complete_date=None, zone="", price=0, memo="", job_id=""):
    client = get_connection()
    sheet = client.open('battery_db').worksheet(NEW_SHEET_NAME)
    all_records = sheet.get_all_records()
    headers = sheet.row_values(1)
    
    try:
        col_status = headers.index('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹') + 1
        col_end = headers.index('å®Œäº†æ—¥') + 1
        col_zone = headers.index('ã‚¨ãƒªã‚¢') + 1
        col_price = headers.index('é‡‘é¡') + 1
        col_memo = headers.index('å‚™è€ƒ') + 1
        col_job = headers.index('ã‚¸ãƒ§ãƒ–ID') + 1 if 'ã‚¸ãƒ§ãƒ–ID' in headers else None
    except: return 0

    cells = []
    target_set = set(str(s) for s in target_serials)
    
    # --- Strict Validation Start ---
    # ã¾ãšå…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆSNã®ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç‰¹å®š
    sn_status_map = {}
    for row in all_records:
        r_sn = str(row.get('ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼', ''))
        if r_sn in target_set:
            sn_status_map[r_sn] = str(row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')).strip()
    
    # æ¤œè¨¼1: DBã«å­˜åœ¨ã—ãªã„SNãŒã‚ã‚‹ã‹
    missing_sns = target_set - set(sn_status_map.keys())
    if missing_sns:
        return {"error": True, "msg": f"æœªç™»éŒ²ã®ãƒãƒƒãƒ†ãƒªãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {', '.join(missing_sns)}"}
    
    # æ¤œè¨¼2: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒå¯¾è±¡å¤–(åœ¨åº«/å‡ºåº«ä¸­ä»¥å¤–)ã®ã‚‚ã®ãŒã‚ã‚‹ã‹
    permitted_statuses = ['åœ¨åº«', 'å‡ºåº«ä¸­']
    invalid_sns = []
    for sn, st_val in sn_status_map.items():
        if st_val not in permitted_statuses:
            invalid_sns.append(f"{sn}({st_val})")
            
    if invalid_sns:
        return {"error": True, "msg": f"å¯¾è±¡å¤–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ãƒãƒƒãƒ†ãƒªãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {', '.join(invalid_sns)}"}
    # --- Strict Validation End ---

    comp_str = sanitize_for_json(complete_date)
    safe_price = int(price)

    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é€šéå¾Œã€æ›´æ–°å‡¦ç†
    updated = 0
    for i, row in enumerate(all_records):
        s = str(row.get('ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼', ''))
        if s in target_set:
            r = i + 2
            cells.append(gspread.Cell(r, col_status, new_status))
            cells.append(gspread.Cell(r, col_end, comp_str))
            cells.append(gspread.Cell(r, col_zone, zone))
            cells.append(gspread.Cell(r, col_price, safe_price))
            if memo: cells.append(gspread.Cell(r, col_memo, memo))
            if col_job and job_id: cells.append(gspread.Cell(r, col_job, job_id))
            updated += 1
            
    if cells:
        try: sheet.update_cells(cells)
        except: return {"error": True, "msg": "DBæ›´æ–°ã‚¨ãƒ©ãƒ¼"}
    
    if updated > 0 and new_status == 'è£œå……æ¸ˆ' and complete_date:
        recalc_weekly_revenue(sheet, complete_date)
        update_analytics_background()

    return {"error": False, "count": updated}

# --- UIãƒ‘ãƒ¼ãƒ„ ---
def create_card(row, today):
    start_date = row.get('ä¿æœ‰é–‹å§‹æ—¥')
    status = str(row.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '')).strip()
    sn = row['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼']
    last4 = sn[-4:]
    
    if pd.isnull(start_date):
        s_str, days = "-", 0
    else:
        s_str = start_date.strftime('%m/%d')
        days = (today - start_date).days
    
    if status == 'è£œå……æ¸ˆ':
        c, bg, st_t, bd = "#1565c0", "#e3f2fd", "âœ… å®Œäº†", "#2196f3"
        date_label = f"å®Œäº†: {s_str}"
        main_text = "è£œå……æ¸ˆ"
    elif status == 'å‡ºåº«ä¸­':
        c, bg, st_t, bd = "#f57c00", "#fff3e0", "ğŸšš å‡ºåº«ä¸­", "#ff9800"
        date_label = f"å–å¾—: {s_str}"
        main_text = last4
    elif status == 'ä¸æ˜' or 'å‰Šé™¤' in status or 'ã‚¨ãƒ©ãƒ¼' in status:
        c, bg, st_t, bd = "#757575", "#f5f5f5", "ğŸš« é™¤å¤–", "#bdbdbd"
        date_label = "-"
        main_text = "é™¤å¤–æ¸ˆ"
    else:
        p_days = PENALTY_LIMIT_DAYS - days
        if p_days <= 5: 
            c, bg, st_t, bd = "#c62828", "#ffebee", f"ğŸ”¥ æ®‹{p_days}æ—¥", "#ef5350"
        elif days <= 3: 
            c, bg, st_t, bd = "#2e7d32", "#e8f5e9", "ğŸ’ Bonuså¯¾è±¡", "#66bb6a"
        else: 
            c, bg, st_t, bd = "#424242", "#ffffff", "ğŸ¢ é€šå¸¸", "#bdbdbd"
        date_label = f"å–å¾—: {s_str}"
        main_text = last4

    html = f"""
    <div style="background:{bg}; border-radius:8px; border-left:6px solid {bd}; padding:10px; margin-bottom:8px; box-shadow:0 1px 3px rgba(0,0,0,0.1);">
        <div style="display:flex; justify-content:space-between; font-size:11px; font-weight:bold; color:{c};">
            <div>{st_t}</div><div>{date_label}</div>
        </div>
        <div style="font-size:28px; font-weight:900; color:#212121; margin-top:2px; letter-spacing:1px;">{main_text}</div>
        <div style="text-align:right; font-size:9px; color:#999; font-family:monospace;">{sn}</div>
    </div>
    """
    return html

# --- ãƒ¡ã‚¤ãƒ³ ---
def main():
    st.set_page_config(page_title="Battery Manager V34", page_icon="âš¡", layout="wide")
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""<div style='display: flex; align-items: center; border-bottom: 2px solid #ff7043; padding-bottom: 10px; margin-bottom: 20px;'><div style='font-size: 40px; margin-right: 15px;'>âš¡</div><div><h1 style='margin: 0; padding: 0; font-size: 32px; color: #333; font-family: sans-serif; letter-spacing: -1px;'>Battery Manager</h1><div style='font-size: 14px; color: #757575;'>Pure Instrument <span style='color: #ff7043; font-weight: bold; margin-left:8px;'>V34 (Strict & JobView)</span></div></div></div>""", unsafe_allow_html=True)

    st.markdown("<style>.stSlider{padding-top:1rem;}</style>", unsafe_allow_html=True)
    today = get_today_jst()

    if 'stocktake_buffer' not in st.session_state: st.session_state['stocktake_buffer'] = []
    if 'parsed_data' not in st.session_state: st.session_state['parsed_data'] = None

    df_all = get_database()
    
    if not df_all.empty and 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in df_all.columns:
        df_valid = df_all[~df_all['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'].str.contains('å‰Šé™¤', na=False)]
        df_inv = get_active_inventory(df_valid)
        df_hist = df_valid[df_valid['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] != 'åœ¨åº«'].copy()
    else:
        df_inv = pd.DataFrame()
        df_hist = pd.DataFrame()

    week_earnings = 0
    last_week_earnings = 0
    week_count = 0
    next_bonus_at = 20
    
    if not df_hist.empty:
        start_of_week = today - datetime.timedelta(days=today.weekday())
        last_week_start = start_of_week - datetime.timedelta(days=7)
        
        df_hist['comp_date'] = pd.to_datetime(df_hist['å®Œäº†æ—¥'], errors='coerce')
        
        w_df = df_hist[
            (df_hist['comp_date'].dt.date >= start_of_week) & 
            (df_hist['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'è£œå……æ¸ˆ')
        ].copy()
        
        lw_df = df_hist[
            (df_hist['comp_date'].dt.date >= last_week_start) & 
            (df_hist['comp_date'].dt.date < start_of_week) & 
            (df_hist['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'è£œå……æ¸ˆ')
        ].copy()

        count_mask = w_df.apply(lambda x: 'ãƒœãƒ¼ãƒŠã‚¹' not in str(x['å‚™è€ƒ']), axis=1)
        week_count = len(w_df[count_mask])
        week_earnings = int(w_df['é‡‘é¡'].sum())
        last_week_earnings = int(lw_df['é‡‘é¡'].sum())
        
        if week_count < 20: next_bonus_at = 20
        elif week_count < 50: next_bonus_at = 50
        elif week_count < 100: next_bonus_at = 100
        elif week_count < 150: next_bonus_at = 150
        else: next_bonus_at = 999

    cur_bonus = get_vol_bonus(week_count)

    if next_bonus_at != 999:
        remain = next_bonus_at - week_count
        st.caption(f"ğŸ”¥ ä»Šé€±ã®ç›®æ¨™: {next_bonus_at}æœ¬ã¾ã§ ã‚ã¨**{remain}æœ¬**")
        st.progress(min(week_count / next_bonus_at, 1.0))
    else:
        st.success(f"ğŸ‘‘ MAXãƒ©ãƒ³ã‚¯åˆ°é”ï¼ (+{cur_bonus}å††)")

    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ  ãƒ›ãƒ¼ãƒ ", "ğŸ” æ¤œç´¢", "ğŸ“¦ åœ¨åº«", "ğŸ’° åç›Š", "ğŸ“ æ£šå¸", "ğŸ“Š åˆ†æ"])

    # 1. ãƒ›ãƒ¼ãƒ 
    with tab1:
        c1, c2, c3 = st.columns(3)
        c1.metric("å ±é…¬", f"Â¥ {week_earnings:,}", delta=f"{week_earnings - last_week_earnings:,} å†† (å…ˆé€±æ¯”)")
        c2.metric("æœ¬æ•°", f"{week_count} æœ¬")
        c3.metric("ç¾åœ¨ãƒœãƒŠ", f"+{cur_bonus}å††/æœ¬")
        st.divider()

        mode = st.radio("ä½œæ¥­ãƒ¢ãƒ¼ãƒ‰", ["å–å‡º (ç™»éŒ²)", "è£œå…… (ç¢ºå®š)"], horizontal=True)
        
        if mode == "å–å‡º (ç™»éŒ²)":
            txt = st.text_area("ãƒªã‚¹ãƒˆè²¼ä»˜", height=100, placeholder="ä¿æœ‰ä¸­ãƒªã‚¹ãƒˆã‚’ã“ã“ã«ãƒšãƒ¼ã‚¹ãƒˆ")
            date_in = st.date_input("åŸºæº–æ—¥ (èª­å–ä¸å¯æ™‚)", value=today)
            if st.button("èª­è¾¼", icon=":material/search:"):
                if txt:
                    parsed = extract_serials_with_date(txt, date_in)
                    st.session_state['parsed_data'] = parsed
                    if parsed: st.success(f"{len(parsed)} ä»¶ èª­è¾¼")
                    else: st.warning("ç•ªå·ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            if st.session_state['parsed_data']:
                st.dataframe(pd.DataFrame(st.session_state['parsed_data'], columns=["SN","æ—¥ä»˜"]), hide_index=True)
                if st.button("ç™»éŒ²å®Ÿè¡Œ", type="primary", use_container_width=True):
                    cnt, skip = register_new_inventory(st.session_state['parsed_data'])
                    msg = f"âœ… {cnt}ä»¶ ç™»éŒ²"
                    if skip > 0: msg += f" (æ‰‹å…ƒé‡è¤‡ {skip}ä»¶ ã‚¹ã‚­ãƒƒãƒ—)"
                    st.success(msg)
                    st.session_state['parsed_data'] = None
                    time.sleep(1)
                    st.rerun()

        else: 
            col_d, col_z = st.columns([1,1])
            date_done = col_d.date_input("è£œå……æ—¥", value=today)
            zone = col_z.selectbox("ã‚¨ãƒªã‚¢", ZONE_OPTIONS)
            
            txt = st.text_area("ãƒªã‚¹ãƒˆè²¼ä»˜", height=100, placeholder="å®Œäº†ç”»é¢ã‚’ã“ã“ã«ãƒšãƒ¼ã‚¹ãƒˆ")
            if txt:
                sns = extract_serials_only(txt)
                if sns:
                    st.info(f"{len(sns)}ä»¶ æ¤œå‡º")
                    if st.button("è£œå……ç¢ºå®š", type="primary", use_container_width=True):
                        base = ZONES[zone]
                        now_str = datetime.datetime.now().strftime('%Y%m%d%H%M%S')
                        auto_job_id = f"J{now_str}"
                        
                        # V34: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è¿½åŠ 
                        res = update_status_bulk(sns, "è£œå……æ¸ˆ", date_done, zone, base, job_id=auto_job_id)
                        if isinstance(res, dict) and res.get('error'):
                            st.error(f"â›”ï¸ ã‚¨ãƒ©ãƒ¼: {res['msg']}")
                        else:
                            cnt = res['count'] if isinstance(res, dict) else res
                            st.success(f"âœ… {cnt}ä»¶ æ›´æ–°å®Œäº† (ID: {auto_job_id})")
                            time.sleep(1)
                            st.rerun()

        st.divider()
        st.markdown("##### ğŸ“Œ ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ— (å„ªå…ˆé †)")
        col_sl, _ = st.columns([1,2])
        with col_sl:
            disp_count = st.slider("è¡¨ç¤ºæ•°", 4, 40, 8, step=4)

        if not df_inv.empty:
            df_disp = df_inv.copy()
            def get_priority(row):
                days = (today - row['ä¿æœ‰é–‹å§‹æ—¥']).days
                if days >= (PENALTY_LIMIT_DAYS - 5): return 1
                if days <= 3: return 2
                return 3
            df_disp['rank'] = df_disp.apply(get_priority, axis=1)
            df_disp = df_disp.sort_values(by=['rank', 'ä¿æœ‰é–‹å§‹æ—¥'], ascending=[True, True])
            
            top_n = df_disp.head(disp_count)
            for i in range(0, len(top_n), 4):
                cols = st.columns(4)
                chunk = top_n.iloc[i:i+4]
                for j, (_, row) in enumerate(chunk.iterrows()):
                    with cols[j]:
                        st.markdown(create_card(row, today), unsafe_allow_html=True)
        else: st.info("ç¾åœ¨ã€åœ¨åº«ã¯ã‚ã‚Šã¾ã›ã‚“")

    # 2. æ¤œç´¢
    with tab2:
        date_options = ["æŒ‡å®šãªã—"]
        date_map = {}
        if not df_inv.empty:
            unique_dates = sorted(df_inv['ä¿æœ‰é–‹å§‹æ—¥'].unique(), reverse=True)
            for d in unique_dates:
                if pd.notnull(d):
                    label = d.strftime('%m/%d')
                    date_options.append(label)
                    date_map[label] = d

        c_s1, c_s2 = st.columns(2)
        with c_s1:
            sel_date = st.selectbox("ä¿æœ‰é–‹å§‹æ—¥ (åœ¨åº«ã®ã¿)", date_options)
        with c_s2:
            sn_in = st.number_input("SNä¸‹4æ¡", 0, 9999, 0)

        results = pd.DataFrame()
        
        if sel_date != "æŒ‡å®šãªã—":
            target_date = date_map[sel_date]
            results = df_inv[df_inv['ä¿æœ‰é–‹å§‹æ—¥'] == target_date].copy()
            if sn_in > 0:
                results = results[results['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].str.endswith(str(sn_in))]
            
            if not results.empty:
                st.success(f"{len(results)}ä»¶ (ä¿æœ‰æ—¥: {sel_date})")
                for _, row in results.iterrows():
                    st.markdown(create_card(row, today), unsafe_allow_html=True)
            else:
                st.warning("è©²å½“ãªã—")

        elif sn_in > 0:
            if not df_all.empty:
                results = df_all[df_all['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].str.endswith(str(sn_in))]
                if not results.empty:
                    st.success(f"{len(results)}ä»¶ ãƒ’ãƒƒãƒˆ (å…¨æœŸé–“)")
                    for _, row in results.iterrows():
                        st.markdown(create_card(row, today), unsafe_allow_html=True)
                else:
                    st.warning("ãªã—")
        else:
            st.info("æ¡ä»¶ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")

    # 3. åœ¨åº«
    with tab3:
        st.metric("åœ¨åº«æ•°", f"{len(df_inv)}")
        if not df_inv.empty:
            st.dataframe(df_inv[['ä¿æœ‰é–‹å§‹æ—¥', 'ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼']], use_container_width=True)

    # 4. åç›Š
    with tab4:
        st.metric("ä»Šé€±", f"Â¥{week_earnings:,}", delta=f"{week_earnings - last_week_earnings:,} å†† (å…ˆé€±æ¯”)")
        
        with st.expander("â• éå»ãƒ‡ãƒ¼ã‚¿ã®ç™»éŒ²"):
            with st.form("manual_past_reg"):
                c1, c2 = st.columns(2)
                p_date = c1.date_input("å®Œäº†æ—¥")
                p_count = c2.number_input("æ•°é‡", min_value=1, value=1)
                p_amount = c1.number_input("åˆè¨ˆé‡‘é¡", step=10)
                p_zone = c2.selectbox("ã‚¨ãƒªã‚¢", ZONE_OPTIONS)
                p_memo = st.text_input("å‚™è€ƒ", placeholder="ãƒœãƒ¼ãƒŠã‚¹ãªã©")
                
                if st.form_submit_button("ç™»éŒ²"):
                    now_str = datetime.datetime.now().strftime('%Y%m%d%H%M%S')
                    auto_job_id = f"J{now_str}"
                    reg_cnt = register_past_bulk(p_date, p_count, p_amount, p_zone, p_memo, job_id=auto_job_id)
                    st.success(f"{reg_cnt}è¡Œ ç™»éŒ²å®Œäº† (ID: {auto_job_id})")
                    time.sleep(1)
                    st.rerun()
        
        st.divider()
        st.subheader("ğŸ“Š å±¥æ­´ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ (Job Group View)")

        if not df_hist.empty:
            df_done = df_hist[df_hist['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'] == 'è£œå……æ¸ˆ'].copy()
            if not df_done.empty:
                # JobIDã§ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ï¼ˆJobIDãŒãªã„ã‚‚ã®ã¯ç©ºæ–‡å­—ã¨ã—ã¦æ‰±ã†ï¼‰
                # ä¸¦ã³é †: JobIDã®é™é †ï¼ˆæ™‚ç³»åˆ—ï¼‰
                df_done['ã‚¸ãƒ§ãƒ–ID'] = df_done['ã‚¸ãƒ§ãƒ–ID'].fillna('')
                # JobIDãŒãªã„å ´åˆã¯æ—¥ä»˜ã§ä»£ç”¨ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ã‚­ãƒ¼ä½œæˆ
                df_done['group_key'] = df_done.apply(lambda x: x['ã‚¸ãƒ§ãƒ–ID'] if x['ã‚¸ãƒ§ãƒ–ID'] else f"NO-JOB-{x['å®Œäº†æ—¥']}", axis=1)
                
                # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦é›†è¨ˆ
                jobs = []
                grouped = df_done.groupby('group_key')
                
                for key, group in grouped:
                    first_row = group.iloc[0]
                    job_id = first_row['ã‚¸ãƒ§ãƒ–ID']
                    date_val = first_row['å®Œäº†æ—¥']
                    area_val = first_row['ã‚¨ãƒªã‚¢']
                    total_amt = group['é‡‘é¡'].sum()
                    count = len(group)
                    
                    # SNãƒªã‚¹ãƒˆ
                    sn_list = group['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'].tolist()
                    
                    jobs.append({
                        'key': key, # ã‚½ãƒ¼ãƒˆç”¨
                        'job_id': job_id,
                        'date': date_val,
                        'area': area_val,
                        'amount': total_amt,
                        'count': count,
                        'sns': sn_list
                    })
                
                # ã‚½ãƒ¼ãƒˆ (Keyã®é™é † = æ–°ã—ã„é †)
                jobs.sort(key=lambda x: x['key'], reverse=True)
                
                for j in jobs:
                    # ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
                    job_label = j['job_id'] if j['job_id'] else "Legacy Job (No ID)"
                    
                    # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒ‰HTML
                    card_html = f"""
                    <div style="background:#ffffff; border:1px solid #e0e0e0; border-radius:8px; padding:12px; margin-bottom:5px; border-left: 5px solid #1565c0;">
                        <div style="display:flex; justify-content:space-between; align-items:center;">
                            <div>
                                <div style="font-size:12px; color:#757575; font-weight:bold;">{j['date']} | {j['area']}</div>
                                <div style="font-size:16px; color:#212121; font-weight:bold;">{job_label}</div>
                            </div>
                            <div style="text-align:right;">
                                <div style="font-size:20px; font-weight:900; color:#1565c0;">Â¥{j['amount']:,}</div>
                                <div style="font-size:11px; color:#757575;">{j['count']}æœ¬</div>
                            </div>
                        </div>
                    </div>
                    """
                    st.markdown(card_html, unsafe_allow_html=True)
                    with st.expander(f"è©³ç´°ã‚’è¦‹ã‚‹ ({len(j['sns'])}æœ¬)"):
                        st.write(", ".join(j['sns']))

    # 5. æ£šå¸
    with tab5:
        st.subheader("åœ¨åº«æ£šå¸ã—")
        cur = st.session_state['stocktake_buffer']
        c1, c2 = st.columns([1,1])
        with c1:
            txt_stock = st.text_area("å…¨ãƒªã‚¹ãƒˆè²¼ä»˜")
            if st.button("ãƒªã‚¹ãƒˆã‚’èª­è¾¼"):
                if txt_stock:
                    add = extract_serials_with_date(txt_stock, today)
                    st.session_state['stocktake_buffer'] = add
                    st.rerun()
            if st.button("ã‚¯ãƒªã‚¢"):
                st.session_state['stocktake_buffer'] = []
                st.rerun()
        with c2:
            st.caption(f"èª­è¾¼: {len(cur)}ä»¶")
            if cur: st.dataframe(pd.DataFrame(cur, columns=["SN","æ—¥ä»˜"]), height=150, hide_index=True)

        st.divider()
        if cur:
            s_map = {s:d for s,d in cur}
            input_set = set(s_map.keys())
            db_map = {}
            if not df_inv.empty:
                db_map = dict(zip(df_inv['ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼'], df_inv['ä¿æœ‰é–‹å§‹æ—¥']))
            db_set = set(db_map.keys())
            missing_db = []
            for s, d in s_map.items():
                if s not in db_map: missing_db.append((s, d))
            ghosts = list(db_set - input_set)
            
            c_act1, c_act2 = st.columns(2)
            with c_act1:
                st.markdown(f"**â‘  æ–°è¦åœ¨åº«: {len(missing_db)}ä»¶**")
                if missing_db:
                    if st.button("æ–°è¦åˆ†ã‚’ç™»éŒ²", type="primary"):
                        cnt, _ = register_new_inventory(missing_db)
                        st.success(f"{cnt}ä»¶ ç™»éŒ²ã—ã¾ã—ãŸ")
                        time.sleep(1)
                        st.rerun()
            with c_act2:
                st.markdown(f"**â‘¡ æ¶ˆå¤±ãƒ»ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥: {len(ghosts)}ä»¶**")
                if ghosts:
                    st.warning("åœ¨åº«å·®ç•°ã‚ã‚Š")
                    with st.expander("è©³ç´°"): st.write(ghosts)
                    if st.button("ä¸€æ‹¬ã€Œè£œå……ã‚¨ãƒ©ãƒ¼ã€ã«ã™ã‚‹"):
                        # V34: æ£šå¸ã—ã®ä¸€æ‹¬ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚‚ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œ
                        res = update_status_bulk(ghosts, "è£œå……ã‚¨ãƒ©ãƒ¼", today, "", 0, "æ£šå¸æ¤œçŸ¥")
                        if isinstance(res, dict) and res.get('error'):
                            st.error(res['msg'])
                        else:
                            cnt = res['count'] if isinstance(res, dict) else res
                            st.success(f"{cnt}ä»¶ ã‚’åœ¨åº«ã‹ã‚‰é™¤å¤–ã—ã¾ã—ãŸ")
                            time.sleep(1)
                            st.rerun()
                else: st.success("å·®ç•°ãªã—")

    # 6. åˆ†æ (Analytics)
    with tab6:
        st.subheader("ğŸ“Š Analytics: Pure Instrument")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        analytics_data = load_analytics_cache()
        
        if not analytics_data:
            st.info("ãƒ‡ãƒ¼ã‚¿é›†è¨ˆå¾…ã¡... ä»»æ„ã®ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œã™ã‚‹ã¨åˆå›è¨ˆç®—ãŒå§‹ã¾ã‚Šã¾ã™ã€‚")
            if st.button("å¼·åˆ¶ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥"):
                update_analytics_background()
                st.success("è¨ˆç®—é–‹å§‹ã€‚ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        else:
            sc = analytics_data.get('scorecard', {})
            cur = sc.get('current', {})
            prev = sc.get('previous', {})
            tactical = analytics_data.get('tactical', {})

            # --- Section 1: Head-Up Display (Comparison) ---
            st.markdown("#### 1. The Head-Up Display (vs Last Week)")
            c_k1, c_k2, c_k3 = st.columns(3)
            
            # Early Bonus Rate
            ebr_cur = cur.get('ebr', 0)
            ebr_prev = prev.get('ebr', 0)
            c_k1.metric(
                label="ğŸ† Early Bonus Rate (å‹ç‡)",
                value=f"{ebr_cur:.1f}%",
                delta=f"{ebr_cur - ebr_prev:.1f}% (vs LW)"
            )
            # RPD
            rpd_cur = cur.get('rpd', 0)
            rpd_prev = prev.get('rpd', 0)
            c_k2.metric(
                label="ğŸ’° RPD (è³‡ç”£å›è»¢é€Ÿåº¦)",
                value=f"Â¥{int(rpd_cur)}/day",
                delta=f"{int(rpd_cur - rpd_prev)} (vs LW)"
            )
            # Avg Holding Days
            ahd_cur = cur.get('ahd', 0)
            ahd_prev = prev.get('ahd', 0)
            c_k3.metric(
                label="âš¡ Avg. Holding Days (é®®åº¦)",
                value=f"{ahd_cur:.1f} days",
                delta=f"{ahd_cur - ahd_prev:.1f} (vs LW)",
                delta_color="inverse" # å¢—ãˆã‚‹ï¼æ‚ªåŒ–ãªã®ã§è‰²åè»¢
            )
            st.divider()

            # --- Section 2: Tactical Metrics ---
            st.markdown("#### 2. Tactical Metrics")
            t_c1, t_c2 = st.columns(2)
            
            # APU (Avg Price Unit)
            apu = cur.get('avg_price', 0)
            apu_delta = apu - 70 # ã‚¨ãƒªã‚¢DåŸºæº–(70å††)ã¨ã®ä¹–é›¢
            t_c1.metric(
                label="ğŸ’ APU (å¹³å‡å˜ä¾¡)",
                value=f"Â¥{int(apu)}",
                delta=f"{int(apu_delta)} vs Std(Â¥70)"
            )
            
            # I/O Balance
            io = tactical.get('io_balance', 0)
            t_c2.metric(
                label="âš–ï¸ I/O Balance (å…¥åº«/å‡ºåº«)",
                value=f"{io:.2f}",
                delta="Overstock" if io > 1.1 else ("Drain" if io < 0.9 else "Balanced"),
                delta_color="off"
            )
            st.caption(f"Input: {tactical.get('input_count')} / Output: {tactical.get('output_count')} (Last 7 Days)")
            st.divider()

            # --- Section 3: Cycle Histogram + Density ---
            st.markdown("#### 3. Cycle Distribution (Histogram + Density)")
            raw_days = analytics_data.get('histogram_raw', [])
            if raw_days:
                hist_source = pd.DataFrame({'days': raw_days})
                hist_source['zone'] = hist_source['days'].apply(
                    lambda x: 'A(0-3)' if x <= 3 else ('B(4-22)' if x <= 22 else 'C(23+)')
                )

                base = alt.Chart(hist_source).encode(x=alt.X('days', title='ä¿æœ‰æ—¥æ•°', bin=alt.Bin(maxbins=30)))

                # 1. Histogram
                bars = base.mark_bar(opacity=0.6).encode(
                    y=alt.Y('count()', title='æœ¬æ•°'),
                    color=alt.Color('zone', scale=alt.Scale(range=['#4caf50', '#ffeb3b', '#f44336']))
                )
                
                # 2. Density Curve
                density = alt.Chart(hist_source).transform_density(
                    'days',
                    as_=['days', 'density'],
                ).mark_line(color='white', strokeWidth=3).encode(
                    x='days:Q',
                    y=alt.Y('density:Q', axis=None) # è»¸ã¯éš ã™
                )
                
                # Peak Indicator logic (Altairä¸Šã§ã¯é›£ã—ã„ã®ã§ç°¡æ˜“çš„ã«å¹³å‡ç·šã‚’è¡¨ç¤º)
                rule = alt.Chart(hist_source).mark_rule(color='red', strokeDash=[5,5]).encode(
                    x='mean(days):Q'
                )

                st.altair_chart((bars + density + rule).resolve_scale(y='independent'), use_container_width=True)
            
            # --- Section 4: Activity Heatmap ---
            st.markdown("#### 4. Activity Heatmap (Past 30 Days)")
            hm_d = analytics_data.get('heatmap', [])
            if hm_d:
                hm_df = pd.DataFrame(hm_d)
                days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                
                chart_heat = alt.Chart(hm_df).mark_rect().encode(
                    x=alt.X('weekday', sort=days_order, title=None),
                    y=alt.Y('count', title='å®Œäº†æœ¬æ•°'), # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—çš„è¡¨ç¾ã ãŒæ£’ã®é«˜ã•ã‚‚åˆ©ç”¨
                    color=alt.Color('count', scale=alt.Scale(scheme='inferno'), title='Intensity'),
                    tooltip=['weekday', 'count']
                ).properties(height=200)
                st.altair_chart(chart_heat, use_container_width=True)

            # --- Section 5: Trend ---
            st.markdown("#### 5. Efficiency Trend (90 Days)")
            tr_d = analytics_data.get('trend', [])
            if tr_d:
                tr_df = pd.DataFrame(tr_d)
                chart_trend = alt.Chart(tr_df).mark_line(point=True).encode(
                    x=alt.X('week', title='é€±'),
                    y=alt.Y('avg_days', title='å¹³å‡ä¿æœ‰æ—¥æ•°', scale=alt.Scale(zero=False)),
                    tooltip=['week', 'avg_days']
                ).properties(height=250)
                st.altair_chart(chart_trend, use_container_width=True)

            st.caption(f"Last Updated: {analytics_data.get('updated_at', '-')}")

if __name__ == '__main__':
    main()
